{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import warnings as wn\n",
    "import sklearn.preprocessing as skpre\n",
    "import category_encoders as ce\n",
    "\n",
    "wn.simplefilter( \"ignore\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparamos los Sets de Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_ts = r\"D:\\FacundoTorraca\\Documents\\TP2_Machine_Learning\\Training Sets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_18_20 = pd.read_csv( loc_ts + \"\\\\ins_18_20.csv\" ); \n",
    "ins_21_23 = pd.read_csv( loc_ts + \"\\\\ins_21_23.csv\" ); \n",
    "ins_24_26 = pd.read_csv( loc_ts + \"\\\\ins_24_26.csv\" ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_18_20 = pd.read_csv( loc_ts + \"\\\\evt_18_20.csv\" );\n",
    "evt_21_23 = pd.read_csv( loc_ts + \"\\\\evt_21_23.csv\" );\n",
    "evt_24_26 = pd.read_csv( loc_ts + \"\\\\evt_24_26.csv\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genero los Sets con el primer install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_18_20[\"date\"] =  pd.to_datetime( ins_18_20[\"date\"] ); ins_18_20[\"_sc\"] = ins_18_20[\"date\"] - dt.datetime( year = 2019, month = 4, day = 18 ); ins_18_20[\"_sc\"] = ins_18_20[\"_sc\"].dt.total_seconds();\n",
    "ins_21_23[\"date\"] =  pd.to_datetime( ins_21_23[\"date\"] ); ins_21_23[\"_sc\"] = ins_21_23[\"date\"] - dt.datetime( year = 2019, month = 4, day = 21 ); ins_21_23[\"_sc\"] = ins_21_23[\"_sc\"].dt.total_seconds(); \n",
    "ins_24_26[\"date\"] =  pd.to_datetime( ins_24_26[\"date\"] ); ins_24_26[\"_sc\"] = ins_24_26[\"date\"] - dt.datetime( year = 2019, month = 4, day = 24 ); ins_24_26[\"_sc\"] = ins_24_26[\"_sc\"].dt.total_seconds(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_18_20_first_ins = ins_18_20.sort_values( by = [\"ref_hash\",\"_sc\"], ascending = True ).drop_duplicates( subset = [\"ref_hash\"], keep = \"first\" )\n",
    "ins_21_23_first_ins = ins_21_23.sort_values( by = [\"ref_hash\",\"_sc\"], ascending = True ).drop_duplicates( subset = [\"ref_hash\"], keep = \"first\" )\n",
    "ins_24_26_first_ins = ins_24_26.sort_values( by = [\"ref_hash\",\"_sc\"], ascending = True ).drop_duplicates( subset = [\"ref_hash\"], keep = \"first\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sacamos los Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_ftr = r\"D:\\FacundoTorraca\\Documents\\TP2_Machine_Learning\\Features\\ftr_ins\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_18_20 = ins_18_20_first_ins[ [\"ref_hash\"] ] #RH unicos que coinciden con los datos que usamos para entrenar\n",
    "rh_21_23 = ins_21_23_first_ins[ [\"ref_hash\"] ] #RH unicos que coinciden con los datos que queremos predecir\n",
    "\n",
    "tg_18_20 = ins_18_20_first_ins[ [\"_sc\"] ]\n",
    "tg_21_23 = ins_21_23_first_ins[ [\"_sc\"] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:yellow\"> ============================================================================================================================ </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Horario del primer evento en ese ventana** </span> \n",
    "\n",
    "Al agregarle la transformacion senoidal para agregarle perdiodicidad a la hora, la prediccion del algoritmo fue peor por lo que decidimos no agregarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_f_evt_18_20 = rh_18_20.copy()\n",
    "hr_f_evt_21_23 = rh_21_23.copy()\n",
    "\n",
    "first_evt_hour_18_20 = evt_18_20[ [\"ref_hash\",\"date\"] ].sort_values( \"date\" ).drop_duplicates( subset = \"ref_hash\", keep = \"first\" )\n",
    "first_evt_hour_21_23 = evt_21_23[ [\"ref_hash\",\"date\"] ].sort_values( \"date\" ).drop_duplicates( subset = \"ref_hash\", keep = \"first\" )\n",
    "\n",
    "first_evt_hour_18_20[\"time_to_frt_evt\"] = ( pd.to_datetime( first_evt_hour_18_20[\"date\"] ) -  dt.datetime( year = 2019, month = 4, day = 18 ) ).dt.total_seconds()\n",
    "first_evt_hour_21_23[\"time_to_frt_evt\"] = ( pd.to_datetime( first_evt_hour_21_23[\"date\"] ) -  dt.datetime( year = 2019, month = 4, day = 21 ) ).dt.total_seconds()\n",
    "\n",
    "first_evt_hour_18_20[\"hour_frt_evt\"] = pd.to_datetime( first_evt_hour_18_20[\"date\"] ).dt.hour\n",
    "first_evt_hour_21_23[\"hour_frt_evt\"] = pd.to_datetime( first_evt_hour_21_23[\"date\"] ).dt.hour\n",
    "\n",
    "first_evt_hour_18_20.drop( [\"date\", \"time_to_frt_evt\"], axis = 1, inplace = True )\n",
    "first_evt_hour_21_23.drop( [\"date\", \"time_to_frt_evt\"], axis = 1, inplace = True )\n",
    "\n",
    "hr_f_evt_18_20 = hr_f_evt_18_20.merge( first_evt_hour_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "hr_f_evt_21_23 = hr_f_evt_21_23.merge( first_evt_hour_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "#hr_f_evt_18_20[\"hour_frt_evt\"] = hr_f_evt_18_20[\"hour_frt_evt\"].apply( lambda x: np.sin( (x *np.pi)/24 ) )\n",
    "#hr_f_evt_21_23[\"hour_frt_evt\"] = hr_f_evt_21_23[\"hour_frt_evt\"].apply( lambda x: np.sin( (x *np.pi)/24 ) )\n",
    "\n",
    "hr_f_evt_18_20.to_csv( loc_ftr + \"\\\\hr_f_evt_18_20.csv\", index = False )\n",
    "hr_f_evt_21_23.to_csv( loc_ftr + \"\\\\hr_f_evt_21_23.csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien hay varios valores NaN en el feature, lo decidimos probar de igual manera, ya que los algoritmos de boosting aceptan valores NaNs.\n",
    "\n",
    "* https://datascience.stackexchange.com/questions/15305/how-does-xgboost-learn-what-are-the-inputs-for-missing-values/15306#15306\n",
    "* The procedure is described in [their paper, section 3.4: Sparsity aware split-finding](https://arxiv.org/pdf/1603.02754v3.pdf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **Cantidad de Eventos por dispositivo en la ventana previa a la conversion** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cant_evt_18_20 = rh_18_20\n",
    "cant_evt_21_23 = rh_21_23\n",
    "\n",
    "cant_evt_18_20 = cant_evt_18_20.merge( evt_18_20[\"ref_hash\"].value_counts().to_frame().reset_index().rename( columns = {\"ref_hash\": \"cant_evt\", \"index\":\"ref_hash\"} ), how = \"left\", on = \"ref_hash\" )\n",
    "cant_evt_21_23 = cant_evt_21_23.merge( evt_21_23[\"ref_hash\"].value_counts().to_frame().reset_index().rename( columns = {\"ref_hash\": \"cant_evt\", \"index\":\"ref_hash\"} ), how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "cant_evt_18_20.fillna( 0, inplace = True )\n",
    "cant_evt_21_23.fillna( 0, inplace = True )\n",
    "\n",
    "cant_evt_18_20.to_csv( loc_ftr + \"\\\\cant_evt_18_20.csv\", index = False )\n",
    "cant_evt_21_23.to_csv( loc_ftr + \"\\\\cant_evt_21_23.csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Cantidad de eventos atribuidas por dispositivo** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cevt_atr_18_20 = rh_18_20.copy()\n",
    "cevt_atr_21_23 = rh_21_23.copy()\n",
    "\n",
    "cant_atr_evt_18_20 = evt_18_20[[\"ref_hash\", \"attributed\"]]; cant_atr_evt_18_20[\"attributed\"] = cant_atr_evt_18_20[\"attributed\"].apply( lambda x: 1 if x else 0 );\n",
    "cant_atr_evt_21_23 = evt_21_23[[\"ref_hash\", \"attributed\"]]; cant_atr_evt_21_23[\"attributed\"] = cant_atr_evt_21_23[\"attributed\"].apply( lambda x: 1 if x else 0 );\n",
    "\n",
    "cant_atr_evt_18_20 = cant_atr_evt_18_20.groupby( \"ref_hash\" ).agg( \"sum\" )\n",
    "cant_atr_evt_21_23 = cant_atr_evt_21_23.groupby( \"ref_hash\" ).agg( \"sum\" )\n",
    "\n",
    "cevt_atr_18_20 = cevt_atr_18_20.merge( cant_atr_evt_18_20, how = \"left\", on = \"ref_hash\" ).fillna( 0 )\n",
    "cevt_atr_21_23 = cevt_atr_21_23.merge( cant_atr_evt_21_23, how = \"left\", on = \"ref_hash\" ).fillna( 0 )\n",
    "\n",
    "cevt_atr_18_20.to_csv( loc_ftr + \"\\\\cevt_atr_18_20.csv\", index = False )\n",
    "cevt_atr_21_23.to_csv( loc_ftr + \"\\\\cevt_atr_21_23.csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Tiempo hasta el primer evento en ese ventana** </span> \n",
    "\n",
    "Le asignamos cuanto tiempo, en la ventana del 18-20, tardo en realizar su primer evento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "frst_evt_18_20 = rh_18_20.copy()\n",
    "frst_evt_21_23 = rh_21_23.copy()\n",
    "\n",
    "first_event_rh_ins_18_20 = evt_18_20[ [\"ref_hash\",\"date\"] ].sort_values( \"date\" ).drop_duplicates( subset = \"ref_hash\", keep = \"first\" )\n",
    "first_event_rh_ins_21_23 = evt_21_23[ [\"ref_hash\",\"date\"] ].sort_values( \"date\" ).drop_duplicates( subset = \"ref_hash\", keep = \"first\" )\n",
    "\n",
    "first_event_rh_ins_18_20[\"time_to_frt_evt\"] = ( pd.to_datetime( first_event_rh_ins_18_20[\"date\"] ) -  dt.datetime( year = 2019, month = 4, day = 18 ) ).dt.total_seconds()\n",
    "first_event_rh_ins_21_23[\"time_to_frt_evt\"] = ( pd.to_datetime( first_event_rh_ins_21_23[\"date\"] ) -  dt.datetime( year = 2019, month = 4, day = 21 ) ).dt.total_seconds()\n",
    "\n",
    "first_event_rh_ins_18_20.drop( \"date\", axis = 1, inplace = True )\n",
    "first_event_rh_ins_21_23.drop( \"date\", axis = 1, inplace = True )\n",
    "\n",
    "frst_evt_18_20 = frst_evt_18_20.merge( first_event_rh_ins_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "frst_evt_21_23 = frst_evt_21_23.merge( first_event_rh_ins_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "#Los que tienen NaN es que nunca convirtieron. Los marcamos con el tiempo maximo\n",
    "frst_evt_18_20.fillna( 3 * 24 * 3600, inplace = True )\n",
    "frst_evt_21_23.fillna( 3 * 24 * 3600, inplace = True )\n",
    "\n",
    "frst_evt_18_20.to_csv( loc_ftr + \"\\\\frst_evt_18_20.csv\", index = False )\n",
    "frst_evt_21_23.to_csv( loc_ftr + \"\\\\frst_evt_21_23.csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Tipo de evento mas realizado por el dispositivo** </span> \n",
    "\n",
    "#### <span style=\"color:orange\"> **Mean Encoding** </span> (Lo codificamos haciendo la cantidad de eventos que se realizaron de ese tipo sobre el total de eventos realizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "kind_evt_18_20 = rh_18_20.copy()\n",
    "kind_evt_21_23 = rh_21_23.copy()\n",
    "\n",
    "main_kind_evt_18_20 = evt_18_20.groupby( by = [\"ref_hash\",\"kind\"] ).agg( {\"kind\":\"count\"} ).rename( columns = {\"kind\":\"cant_evt\"} ).reset_index()\n",
    "main_kind_evt_21_23 = evt_21_23.groupby( by = [\"ref_hash\",\"kind\"] ).agg( {\"kind\":\"count\"} ).rename( columns = {\"kind\":\"cant_evt\"} ).reset_index()\n",
    "\n",
    "main_kind_evt_18_20 = main_kind_evt_18_20.sort_values( by = [\"ref_hash\", \"cant_evt\"], ascending = True ).drop_duplicates( subset = \"ref_hash\", keep = \"last\" ); del( main_kind_evt_18_20[\"cant_evt\"] )\n",
    "main_kind_evt_21_23 = main_kind_evt_21_23.sort_values( by = [\"ref_hash\", \"cant_evt\"], ascending = True ).drop_duplicates( subset = \"ref_hash\", keep = \"last\" ); del( main_kind_evt_21_23[\"cant_evt\"] ) \n",
    "\n",
    "kind_evt_18_20 = kind_evt_18_20.merge( main_kind_evt_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "kind_evt_21_23 = kind_evt_21_23.merge( main_kind_evt_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "cant_kind_evt_18_20 = evt_18_20[[\"ref_hash\",\"kind\"]].groupby( \"kind\" ).agg(\"count\").reset_index().rename( columns = {\"ref_hash\":\"cant_kind\"} )\n",
    "cant_kind_evt_21_23 = evt_21_23[[\"ref_hash\",\"kind\"]].groupby( \"kind\" ).agg(\"count\").reset_index().rename( columns = {\"ref_hash\":\"cant_kind\"} )\n",
    "\n",
    "kind_evt_18_20 = kind_evt_18_20.merge( cant_kind_evt_18_20, how = \"left\", on = \"kind\" ).drop( \"kind\", axis = 1 )\n",
    "kind_evt_21_23 = kind_evt_21_23.merge( cant_kind_evt_21_23, how = \"left\", on = \"kind\" ).drop( \"kind\", axis = 1 )\n",
    "\n",
    "kind_evt_18_20[\"kind_mean\"] = kind_evt_18_20[\"cant_kind\"] / len(evt_18_20); kind_evt_18_20.fillna( kind_evt_18_20[\"kind_mean\"].isnull().sum() / len(evt_18_20), inplace = True ); del(kind_evt_18_20[\"cant_kind\"])\n",
    "kind_evt_21_23[\"kind_mean\"] = kind_evt_21_23[\"cant_kind\"] / len(evt_21_23); kind_evt_21_23.fillna( kind_evt_21_23[\"kind_mean\"].isnull().sum() / len(evt_21_23), inplace = True ); del(kind_evt_21_23[\"cant_kind\"])\n",
    "\n",
    "kind_evt_18_20.to_csv( loc_ftr + \"\\\\kind_evt_18_20.csv\", index = False )\n",
    "kind_evt_21_23.to_csv( loc_ftr + \"\\\\kind_evt_21_23.csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **Cantidad de eventos atribuidas por dispositivo** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cevt_atr_18_20 = rh_18_20.copy()\n",
    "cevt_atr_21_23 = rh_21_23.copy()\n",
    "\n",
    "cant_atr_evt_18_20 = evt_18_20[[\"ref_hash\", \"attributed\"]]; cant_atr_evt_18_20[\"attributed\"] = cant_atr_evt_18_20[\"attributed\"].apply( lambda x: 1 if x else 0 );\n",
    "cant_atr_evt_21_23 = evt_21_23[[\"ref_hash\", \"attributed\"]]; cant_atr_evt_21_23[\"attributed\"] = cant_atr_evt_21_23[\"attributed\"].apply( lambda x: 1 if x else 0 );\n",
    "\n",
    "cant_atr_evt_18_20 = cant_atr_evt_18_20.groupby( \"ref_hash\" ).agg( \"sum\" )\n",
    "cant_atr_evt_21_23 = cant_atr_evt_21_23.groupby( \"ref_hash\" ).agg( \"sum\" )\n",
    "\n",
    "cevt_atr_18_20 = cevt_atr_18_20.merge( cant_atr_evt_18_20, how = \"left\", on = \"ref_hash\" ).fillna( 0 )\n",
    "cevt_atr_21_23 = cevt_atr_21_23.merge( cant_atr_evt_21_23, how = \"left\", on = \"ref_hash\" ).fillna( 0 )\n",
    "\n",
    "cevt_atr_18_20.to_csv( loc_ftr + \"\\\\cevt_atr_18_20.csv\", index = False )\n",
    "cevt_atr_21_23.to_csv( loc_ftr + \"\\\\cevt_atr_21_23.csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **Aplicaciones que mas realizaron eventos cada usuario** </span>\n",
    "\n",
    "#### <span style=\"color:orange\"> **Mean Encoding** </span> (Usamos el promedio de la cantidad de veces que que es la app principal de algun dispositivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapp_evt_18_20 = rh_18_20.copy()\n",
    "mapp_evt_21_23 = rh_21_23.copy()\n",
    "\n",
    "app_mas_evt_18_20 = evt_18_20.groupby( by = [\"ref_hash\",\"application_id\"] ).agg( {\"application_id\":\"count\"} ).rename( columns = {\"application_id\":\"cant_evt\"} ).reset_index()\n",
    "app_mas_evt_21_23 = evt_21_23.groupby( by = [\"ref_hash\",\"application_id\"] ).agg( {\"application_id\":\"count\"} ).rename( columns = {\"application_id\":\"cant_evt\"} ).reset_index()\n",
    "\n",
    "app_mas_evt_18_20 = app_mas_evt_18_20.sort_values( by = [\"ref_hash\", \"cant_evt\"], ascending = True ).drop_duplicates( subset = \"ref_hash\", keep = \"last\" ); del( app_mas_evt_18_20[\"cant_evt\"] )\n",
    "app_mas_evt_21_23 = app_mas_evt_21_23.sort_values( by = [\"ref_hash\", \"cant_evt\"], ascending = True ).drop_duplicates( subset = \"ref_hash\", keep = \"last\" ); del( app_mas_evt_21_23[\"cant_evt\"] ) \n",
    "\n",
    "mapp_evt_18_20 = mapp_evt_18_20.merge( app_mas_evt_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "mapp_evt_21_23 = mapp_evt_21_23.merge( app_mas_evt_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "mapp_evt_18_20[\"to_count\"] = 1; mapp_evt_18_20[\"application_id\"] = mapp_evt_18_20[[\"application_id\", \"to_count\"]].groupby(\"application_id\").transform( \"sum\" ) / len(mapp_evt_18_20); del(mapp_evt_18_20[\"to_count\"])\n",
    "mapp_evt_21_23[\"to_count\"] = 1; mapp_evt_21_23[\"application_id\"] = mapp_evt_21_23[[\"application_id\", \"to_count\"]].groupby(\"application_id\").transform( \"sum\" ) / len(mapp_evt_21_23); del(mapp_evt_21_23[\"to_count\"])\n",
    "\n",
    "#Completamos los NaNs con el promedio de su cantidad\n",
    "mapp_evt_18_20[\"application_id\"].fillna( mapp_evt_18_20[\"application_id\"].isnull().sum() / len( mapp_evt_18_20 ) , inplace = True )\n",
    "mapp_evt_21_23[\"application_id\"].fillna( mapp_evt_21_23[\"application_id\"].isnull().sum() / len( mapp_evt_21_23 ), inplace = True )\n",
    "\n",
    "mapp_evt_18_20.to_csv( loc_ftr + \"\\\\mapp_evt_18_20.csv\", index = False )\n",
    "mapp_evt_21_23.to_csv( loc_ftr + \"\\\\mapp_evt_21_23.csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **Cantidad de eventos realizados con WiFi** </span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wifi_evt_18_20 = rh_18_20.copy()\n",
    "wifi_evt_21_23 = rh_21_23.copy()\n",
    "\n",
    "cant_wifi_evt_18_20 = evt_18_20[[\"ref_hash\", \"wifi\"]]; cant_wifi_evt_18_20[\"wifi\"] = cant_wifi_evt_18_20[\"wifi\"].apply( lambda x: 1 if x else 0 );\n",
    "cant_wifi_evt_21_23 = evt_21_23[[\"ref_hash\", \"wifi\"]]; cant_wifi_evt_21_23[\"wifi\"] = cant_wifi_evt_21_23[\"wifi\"].apply( lambda x: 1 if x else 0 );\n",
    "\n",
    "cant_wifi_evt_18_20 = cant_wifi_evt_18_20.groupby( \"ref_hash\" ).agg( \"sum\" )\n",
    "cant_wifi_evt_21_23 = cant_wifi_evt_21_23.groupby( \"ref_hash\" ).agg( \"sum\" )\n",
    "\n",
    "wifi_evt_18_20 = wifi_evt_18_20.merge( cant_wifi_evt_18_20, how = \"left\", on = \"ref_hash\" ).fillna( 0 )\n",
    "wifi_evt_21_23 = wifi_evt_21_23.merge( cant_wifi_evt_21_23, how = \"left\", on = \"ref_hash\" ).fillna( 0 )\n",
    "\n",
    "wifi_evt_18_20.to_csv( loc_ftr + \"\\\\wifi_evt_18_20.csv\", index = False )\n",
    "wifi_evt_21_23.to_csv( loc_ftr + \"\\\\wifi_evt_21_23.csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **Tiempo hasta la ultimo evento en esa ventana** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_evt_18_20 = rh_18_20.copy()\n",
    "last_evt_21_23 = rh_21_23.copy()\n",
    "\n",
    "last_event_rh_ins_18_20 = evt_18_20[ [\"ref_hash\",\"date\"] ].sort_values( \"date\", ascending = False ).drop_duplicates( subset = \"ref_hash\", keep = \"first\" )\n",
    "last_event_rh_ins_21_23 = evt_21_23[ [\"ref_hash\",\"date\"] ].sort_values( \"date\", ascending = False ).drop_duplicates( subset = \"ref_hash\", keep = \"first\" )\n",
    "\n",
    "last_event_rh_ins_18_20[\"time_to_lst_evt\"] = ( pd.to_datetime( last_event_rh_ins_18_20[\"date\"] ) -  dt.datetime( year = 2019, month = 4, day = 18 ) ).dt.total_seconds()\n",
    "last_event_rh_ins_21_23[\"time_to_lst_evt\"] = ( pd.to_datetime( last_event_rh_ins_21_23[\"date\"] ) -  dt.datetime( year = 2019, month = 4, day = 21 ) ).dt.total_seconds()\n",
    "\n",
    "last_event_rh_ins_18_20.drop( \"date\", axis = 1, inplace = True )\n",
    "last_event_rh_ins_21_23.drop( \"date\", axis = 1, inplace = True )\n",
    "\n",
    "last_evt_18_20 = last_evt_18_20.merge( last_event_rh_ins_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "last_evt_21_23 = last_evt_21_23.merge( last_event_rh_ins_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "#Los que tienen NaN es que nunca convirtieron. Los marcamos con el tiempo maximo\n",
    "last_evt_18_20.fillna( 3 * 24 * 3600, inplace = True )\n",
    "last_evt_21_23.fillna( 3 * 24 * 3600, inplace = True )\n",
    "\n",
    "last_evt_18_20.to_csv( loc_ftr + \"\\\\last_evt_18_20.csv\", index = False )\n",
    "last_evt_21_23.to_csv( loc_ftr + \"\\\\last_evt_21_23.csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Hizo eventos entre 21 hs y 3 hs (Noche)** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **Mean Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_18_20['date'] = pd.to_datetime(evt_18_20['date'])\n",
    "evt_21_23['date'] = pd.to_datetime(evt_21_23['date'])\n",
    "\n",
    "evt_18_20['evt_21_3'] = (evt_18_20['date'].dt.hour < 4) | (evt_18_20['date'].dt.hour > 20)\n",
    "evt_21_23['evt_21_3'] = (evt_21_23['date'].dt.hour < 4) | (evt_18_20['date'].dt.hour > 20)\n",
    "\n",
    "evt_night_18_20 = rh_18_20.copy()\n",
    "evt_night_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = evt_18_20.groupby('ref_hash').agg({'evt_21_3':'sum'}).reset_index()\n",
    "hour_mode_21_23 = evt_21_23.groupby('ref_hash').agg({'evt_21_3':'sum'}).reset_index()\n",
    "\n",
    "evt_night_18_20 = evt_night_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "evt_night_21_23 = evt_night_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "evt_night_18_20[\"evt_21_3\"] =  (evt_night_18_20[\"evt_21_3\"] > 1).astype('int8')\n",
    "evt_night_21_23[\"evt_21_3\"] =  (evt_night_21_23[\"evt_21_3\"] > 1).astype('int8')\n",
    "\n",
    "evt_night_18_20['me_evt_21_3'] = ( evt_night_18_20.groupby('evt_21_3').transform('count') ) / len(evt_night_18_20['evt_21_3'])\n",
    "evt_night_21_23['me_evt_21_3'] = ( evt_night_21_23.groupby('evt_21_3').transform('count') ) / len(evt_night_21_23['evt_21_3'])\n",
    "\n",
    "del evt_night_18_20['evt_21_3']\n",
    "del evt_night_21_23['evt_21_3']\n",
    "\n",
    "evt_night_18_20.to_csv( loc_ftr + \"\\\\evt_ngme_18_20.csv\", index = False )\n",
    "evt_night_21_23.to_csv( loc_ftr + \"\\\\evt_ngme_21_23.csv\", index = False )\n",
    "\n",
    "del evt_18_20['evt_21_3']\n",
    "del evt_21_23['evt_21_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **One-Hot Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_18_20['date'] = pd.to_datetime(evt_18_20['date'])\n",
    "evt_21_23['date'] = pd.to_datetime(evt_21_23['date'])\n",
    "\n",
    "evt_18_20['evt_21_3'] = (evt_18_20['date'].dt.hour < 4) | (evt_18_20['date'].dt.hour > 20)\n",
    "evt_21_23['evt_21_3'] = (evt_21_23['date'].dt.hour < 4) | (evt_18_20['date'].dt.hour > 20)\n",
    "\n",
    "evt_night_18_20 = rh_18_20.copy()\n",
    "evt_night_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = evt_18_20.groupby('ref_hash').agg({'evt_21_3':'sum'}).reset_index()\n",
    "hour_mode_21_23 = evt_21_23.groupby('ref_hash').agg({'evt_21_3':'sum'}).reset_index()\n",
    "\n",
    "evt_night_18_20 = evt_night_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "evt_night_21_23 = evt_night_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "evt_night_18_20[\"evt_21_3\"] =  (evt_night_18_20[\"evt_21_3\"] > 1).astype('int8')\n",
    "evt_night_21_23[\"evt_21_3\"] =  (evt_night_21_23[\"evt_21_3\"] > 1).astype('int8')\n",
    "\n",
    "evt_night_18_20.to_csv( loc_ftr + \"\\\\evt_ngoh_18_20.csv\", index = False )\n",
    "evt_night_21_23.to_csv( loc_ftr + \"\\\\evt_ngoh_21_23.csv\", index = False )\n",
    "\n",
    "del evt_18_20['evt_21_3']\n",
    "del evt_21_23['evt_21_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Hizo eventos entre 4 hs y 10 hs (Ma√±ana)** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **Mean Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_18_20['date'] = pd.to_datetime(evt_18_20['date'])\n",
    "evt_21_23['date'] = pd.to_datetime(evt_21_23['date'])\n",
    "\n",
    "evt_18_20['evt_4_10'] = (evt_18_20['date'].dt.hour < 11) & (evt_18_20['date'].dt.hour > 3)\n",
    "evt_21_23['evt_4_10'] = (evt_21_23['date'].dt.hour < 11) & (evt_18_20['date'].dt.hour > 3)\n",
    "\n",
    "evt_morn_18_20 = rh_18_20.copy()\n",
    "evt_morn_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = evt_18_20.groupby('ref_hash').agg({'evt_4_10':'sum'}).reset_index()\n",
    "hour_mode_21_23 = evt_21_23.groupby('ref_hash').agg({'evt_4_10':'sum'}).reset_index()\n",
    "\n",
    "evt_morn_18_20 = evt_morn_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "evt_morn_21_23 = evt_morn_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "evt_morn_18_20[\"evt_4_10\"] =  (evt_morn_18_20[\"evt_4_10\"] > 1).astype('int8')\n",
    "evt_morn_21_23[\"evt_4_10\"] =  (evt_morn_21_23[\"evt_4_10\"] > 1).astype('int8')\n",
    "\n",
    "evt_morn_18_20['me_evt_4_10'] = ( evt_morn_18_20.groupby('evt_4_10').transform('count') ) / len(evt_morn_18_20['evt_4_10'])\n",
    "evt_morn_21_23['me_evt_4_10'] = ( evt_morn_21_23.groupby('evt_4_10').transform('count') ) / len(evt_morn_21_23['evt_4_10'])\n",
    "\n",
    "del evt_morn_18_20['evt_4_10']\n",
    "del evt_morn_21_23['evt_4_10']\n",
    "\n",
    "evt_morn_18_20.to_csv( loc_ftr + \"\\\\evt_mrme_18_20.csv\", index = False )\n",
    "evt_morn_21_23.to_csv( loc_ftr + \"\\\\evt_mrme_21_23.csv\", index = False )\n",
    "\n",
    "del evt_18_20['evt_4_10']\n",
    "del evt_21_23['evt_4_10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **One-Hot Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_18_20['date'] = pd.to_datetime(evt_18_20['date'])\n",
    "evt_21_23['date'] = pd.to_datetime(evt_21_23['date'])\n",
    "\n",
    "evt_18_20['evt_4_10'] = (evt_18_20['date'].dt.hour < 11) & (evt_18_20['date'].dt.hour > 3)\n",
    "evt_21_23['evt_4_10'] = (evt_21_23['date'].dt.hour < 11) & (evt_18_20['date'].dt.hour > 3)\n",
    "\n",
    "evt_morn_18_20 = rh_18_20.copy()\n",
    "evt_morn_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = evt_18_20.groupby('ref_hash').agg({'evt_4_10':'sum'}).reset_index()\n",
    "hour_mode_21_23 = evt_21_23.groupby('ref_hash').agg({'evt_4_10':'sum'}).reset_index()\n",
    "\n",
    "evt_morn_18_20 = evt_morn_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "evt_morn_21_23 = evt_morn_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "evt_morn_18_20[\"evt_4_10\"] =  (evt_morn_18_20[\"evt_4_10\"] > 1).astype('int8')\n",
    "evt_morn_21_23[\"evt_4_10\"] =  (evt_morn_21_23[\"evt_4_10\"] > 1).astype('int8')\n",
    "\n",
    "evt_morn_18_20.to_csv( loc_ftr + \"\\\\evt_mroh_18_20.csv\", index = False )\n",
    "evt_morn_21_23.to_csv( loc_ftr + \"\\\\evt_mroh_21_23.csv\", index = False )\n",
    "\n",
    "del evt_18_20['evt_4_10']\n",
    "del evt_21_23['evt_4_10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Hizo eventos entre 11 hs y 15 hs (Mediodia)** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **Mean Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_18_20['date'] = pd.to_datetime(evt_18_20['date'])\n",
    "evt_21_23['date'] = pd.to_datetime(evt_21_23['date'])\n",
    "\n",
    "evt_18_20['evt_11_15'] = (evt_18_20['date'].dt.hour < 16) & (evt_18_20['date'].dt.hour > 10)\n",
    "evt_21_23['evt_11_15'] = (evt_21_23['date'].dt.hour < 16) & (evt_18_20['date'].dt.hour > 10)\n",
    "\n",
    "evt_midday_18_20 = rh_18_20.copy()\n",
    "evt_midday_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = evt_18_20.groupby('ref_hash').agg({'evt_11_15':'sum'}).reset_index()\n",
    "hour_mode_21_23 = evt_21_23.groupby('ref_hash').agg({'evt_11_15':'sum'}).reset_index()\n",
    "\n",
    "evt_midday_18_20 = evt_midday_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "evt_midday_21_23 = evt_midday_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "evt_midday_18_20[\"evt_11_15\"] =  (evt_midday_18_20[\"evt_11_15\"] > 1).astype('int8')\n",
    "evt_midday_21_23[\"evt_11_15\"] =  (evt_midday_21_23[\"evt_11_15\"] > 1).astype('int8')\n",
    "\n",
    "evt_midday_18_20['me_evt_11_15'] = ( evt_midday_18_20.groupby('evt_11_15').transform('count') ) / len(evt_midday_18_20['evt_11_15'])\n",
    "evt_midday_21_23['me_evt_11_15'] = ( evt_midday_21_23.groupby('evt_11_15').transform('count') ) / len(evt_midday_21_23['evt_11_15'])\n",
    "\n",
    "del evt_midday_18_20['evt_11_15']\n",
    "del evt_midday_21_23['evt_11_15']\n",
    "\n",
    "evt_midday_18_20.to_csv( loc_ftr + \"\\\\me_evt_mdme_18_20.csv\", index = False )\n",
    "evt_midday_21_23.to_csv( loc_ftr + \"\\\\me_evt_mdme_21_23.csv\", index = False )\n",
    "\n",
    "del evt_18_20['evt_11_15']\n",
    "del evt_21_23['evt_11_15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **One-Hot Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_18_20['date'] = pd.to_datetime(evt_18_20['date'])\n",
    "evt_21_23['date'] = pd.to_datetime(evt_21_23['date'])\n",
    "\n",
    "evt_18_20['evt_11_15'] = (evt_18_20['date'].dt.hour < 16) & (evt_18_20['date'].dt.hour > 10)\n",
    "evt_21_23['evt_11_15'] = (evt_21_23['date'].dt.hour < 16) & (evt_18_20['date'].dt.hour > 10)\n",
    "\n",
    "evt_midday_18_20 = rh_18_20.copy()\n",
    "evt_midday_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = evt_18_20.groupby('ref_hash').agg({'evt_11_15':'sum'}).reset_index()\n",
    "hour_mode_21_23 = evt_21_23.groupby('ref_hash').agg({'evt_11_15':'sum'}).reset_index()\n",
    "\n",
    "evt_midday_18_20 = evt_midday_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "evt_midday_21_23 = evt_midday_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "evt_midday_18_20[\"evt_11_15\"] =  (evt_midday_18_20[\"evt_11_15\"] > 1).astype('int8')\n",
    "evt_midday_21_23[\"evt_11_15\"] =  (evt_midday_21_23[\"evt_11_15\"] > 1).astype('int8')\n",
    "\n",
    "evt_midday_18_20.to_csv( loc_ftr + \"\\\\evt_mdoh_18_20.csv\", index = False )\n",
    "evt_midday_21_23.to_csv( loc_ftr + \"\\\\evt_mdoh_21_23.csv\", index = False )\n",
    "\n",
    "del evt_18_20['evt_11_15']\n",
    "del evt_21_23['evt_11_15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Hizo eventos entre 16 hs y 20 hs (Tarde)** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:Orange\"> **Mean Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_18_20['date'] = pd.to_datetime(evt_18_20['date'])\n",
    "evt_21_23['date'] = pd.to_datetime(evt_21_23['date'])\n",
    "\n",
    "evt_18_20['evt_16_20'] = (evt_18_20['date'].dt.hour < 21) & (evt_18_20['date'].dt.hour > 15)\n",
    "evt_21_23['evt_16_20'] = (evt_21_23['date'].dt.hour < 21) & (evt_18_20['date'].dt.hour > 15)\n",
    "\n",
    "evt_after_18_20 = rh_18_20.copy()\n",
    "evt_after_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = evt_18_20.groupby('ref_hash').agg({'evt_16_20':'sum'}).reset_index()\n",
    "hour_mode_21_23 = evt_21_23.groupby('ref_hash').agg({'evt_16_20':'sum'}).reset_index()\n",
    "\n",
    "evt_after_18_20 = evt_after_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "evt_after_21_23 = evt_after_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "evt_after_18_20[\"evt_16_20\"] =  (evt_after_18_20[\"evt_16_20\"] > 1).astype('int8')\n",
    "evt_after_21_23[\"evt_16_20\"] =  (evt_after_21_23[\"evt_16_20\"] > 1).astype('int8')\n",
    "\n",
    "evt_after_18_20['me_evt_16_20'] = ( evt_after_18_20.groupby('evt_16_20').transform('count') ) / len(evt_after_18_20['evt_16_20'])\n",
    "evt_after_21_23['me_evt_16_20'] = ( evt_after_21_23.groupby('evt_16_20').transform('count') ) / len(evt_after_21_23['evt_16_20'])\n",
    "\n",
    "del evt_after_18_20['evt_16_20']\n",
    "del evt_after_21_23['evt_16_20']\n",
    "\n",
    "evt_after_18_20.to_csv( loc_ftr + \"\\\\evt_afme_18_20.csv\", index = False )\n",
    "evt_after_21_23.to_csv( loc_ftr + \"\\\\evt_afme_21_23.csv\", index = False )\n",
    "\n",
    "del evt_18_20['evt_16_20']\n",
    "del evt_21_23['evt_16_20']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:Orange\"> **One-Hot Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_18_20['date'] = pd.to_datetime(evt_18_20['date'])\n",
    "evt_21_23['date'] = pd.to_datetime(evt_21_23['date'])\n",
    "\n",
    "evt_18_20['evt_16_20'] = (evt_18_20['date'].dt.hour < 21) & (evt_18_20['date'].dt.hour > 15)\n",
    "evt_21_23['evt_16_20'] = (evt_21_23['date'].dt.hour < 21) & (evt_18_20['date'].dt.hour > 15)\n",
    "\n",
    "evt_after_18_20 = rh_18_20.copy()\n",
    "evt_after_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = evt_18_20.groupby('ref_hash').agg({'evt_16_20':'sum'}).reset_index()\n",
    "hour_mode_21_23 = evt_21_23.groupby('ref_hash').agg({'evt_16_20':'sum'}).reset_index()\n",
    "\n",
    "evt_after_18_20 = evt_after_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "evt_after_21_23 = evt_after_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "evt_after_18_20[\"evt_16_20\"] =  (evt_after_18_20[\"evt_16_20\"] > 1).astype('int8')\n",
    "evt_after_21_23[\"evt_16_20\"] =  (evt_after_21_23[\"evt_16_20\"] > 1).astype('int8')\n",
    "\n",
    "evt_after_18_20.to_csv( loc_ftr + \"\\\\evt_afoh_18_20.csv\", index = False )\n",
    "evt_after_21_23.to_csv( loc_ftr + \"\\\\evt_afoh_21_23.csv\", index = False )\n",
    "\n",
    "del evt_18_20['evt_16_20']\n",
    "del evt_21_23['evt_16_20']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
