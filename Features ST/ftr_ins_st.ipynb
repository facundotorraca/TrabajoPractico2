{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import warnings as wn\n",
    "import sklearn.preprocessing as skpre\n",
    "import category_encoders as ce\n",
    "\n",
    "wn.simplefilter( \"ignore\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparamos los Sets de Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_ts = r\"D:\\FacundoTorraca\\Documents\\TP2_Machine_Learning\\Training Sets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_18_20 = pd.read_csv( loc_ts + \"\\\\ins_18_20.csv\" ); \n",
    "ins_21_23 = pd.read_csv( loc_ts + \"\\\\ins_21_23.csv\" ); \n",
    "ins_24_26 = pd.read_csv( loc_ts + \"\\\\ins_24_26.csv\" ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_18_20 = pd.read_csv( loc_ts + \"\\\\auc_18_20.csv\" ); \n",
    "auc_21_23 = pd.read_csv( loc_ts + \"\\\\auc_21_23.csv\" );\n",
    "auc_24_26 = pd.read_csv( loc_ts + \"\\\\auc_24_26.csv\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genero los Sets con el primer install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_18_20[\"date\"] =  pd.to_datetime( auc_18_20[\"date\"] ); auc_18_20[\"_st\"] = auc_18_20[\"date\"] - dt.datetime( year = 2019, month = 4, day = 18 ); auc_18_20[\"_st\"] = auc_18_20[\"_st\"].dt.total_seconds();\n",
    "auc_21_23[\"date\"] =  pd.to_datetime( auc_21_23[\"date\"] ); auc_21_23[\"_st\"] = auc_21_23[\"date\"] - dt.datetime( year = 2019, month = 4, day = 21 ); auc_21_23[\"_st\"] = auc_21_23[\"_st\"].dt.total_seconds(); \n",
    "auc_24_26[\"date\"] =  pd.to_datetime( auc_24_26[\"date\"] ); auc_24_26[\"_st\"] = auc_24_26[\"date\"] - dt.datetime( year = 2019, month = 4, day = 24 ); auc_24_26[\"_st\"] = auc_24_26[\"_st\"].dt.total_seconds(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_18_20_first_auc = auc_18_20.sort_values( by = [\"device_id\",\"_st\"], ascending = True ).drop_duplicates( subset = [\"device_id\"], keep = \"first\" ).rename( columns = {\"device_id\": \"ref_hash\"} )\n",
    "auc_21_23_first_auc = auc_21_23.sort_values( by = [\"device_id\",\"_st\"], ascending = True ).drop_duplicates( subset = [\"device_id\"], keep = \"first\" ).rename( columns = {\"device_id\": \"ref_hash\"} )\n",
    "auc_24_26_first_auc = auc_24_26.sort_values( by = [\"device_id\",\"_st\"], ascending = True ).drop_duplicates( subset = [\"device_id\"], keep = \"first\" ).rename( columns = {\"device_id\": \"ref_hash\"} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sacamos los Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_ftr = r\"D:\\FacundoTorraca\\Documents\\TP2_Machine_Learning\\Features\\ftr_auc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_18_20 = auc_18_20_first_auc[ [\"ref_hash\"] ] #RH unicos que coinciden con los datos que usamos para entrenar\n",
    "rh_21_23 = auc_21_23_first_auc[ [\"ref_hash\"] ] #RH unicos que coinciden con los datos que queremos predecir\n",
    "\n",
    "tg_18_20 = auc_18_20_first_auc[ [\"_st\"] ]\n",
    "tg_21_23 = auc_21_23_first_auc[ [\"_st\"] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Tiempo hasta la primer instlacion en ese ventana** </span> \n",
    "\n",
    "Le asignamos cuanto tiempo, en la ventana del 18-20, tardo en realizar su primer instlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frst_ins_18_20 = rh_18_20.copy()\n",
    "frst_ins_21_23 = rh_21_23.copy()\n",
    "\n",
    "first_installs_rh_auc_18_20 = ins_18_20[ [\"ref_hash\",\"date\"] ].sort_values( \"date\" ).drop_duplicates( subset = \"ref_hash\", keep = \"first\" )\n",
    "first_installs_rh_auc_21_23 = ins_21_23[ [\"ref_hash\",\"date\"] ].sort_values( \"date\" ).drop_duplicates( subset = \"ref_hash\", keep = \"first\" )\n",
    "\n",
    "first_installs_rh_auc_18_20[\"time_to_frt_ins\"] = ( pd.to_datetime( first_installs_rh_auc_18_20[\"date\"] ) -  dt.datetime( year = 2019, month = 4, day = 18 ) ).dt.total_seconds()\n",
    "first_installs_rh_auc_21_23[\"time_to_frt_ins\"] = ( pd.to_datetime( first_installs_rh_auc_21_23[\"date\"] ) -  dt.datetime( year = 2019, month = 4, day = 21 ) ).dt.total_seconds()\n",
    "\n",
    "first_installs_rh_auc_18_20.drop( \"date\", axis = 1, inplace = True )\n",
    "first_installs_rh_auc_21_23.drop( \"date\", axis = 1, inplace = True )\n",
    "\n",
    "frst_ins_18_20 = frst_ins_18_20.merge( first_installs_rh_auc_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "frst_ins_21_23 = frst_ins_21_23.merge( first_installs_rh_auc_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "#Los que tienen NaN es que nunca convirtieron. Los marcamos con el tiempo maximo\n",
    "frst_ins_18_20.fillna( 3 * 24 * 3600, inplace = True )\n",
    "frst_ins_21_23.fillna( 3 * 24 * 3600, inplace = True )\n",
    "\n",
    "frst_ins_18_20.to_csv( loc_ftr + \"\\\\frst_ins_18_20.csv\", index = False )\n",
    "frst_ins_21_23.to_csv( loc_ftr + \"\\\\frst_ins_21_23.csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Aplicacion mas instalada por el usuario** </span>\n",
    "\n",
    "#### <span style=\"color:orange\"> **Mean Encoding** </span> (Usamos el promedio de la cantidad de veces que que es la app principal de algun dispositivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_app_18_20 = rh_18_20.copy()\n",
    "main_app_21_23 = rh_21_23.copy()\n",
    "\n",
    "app_mas_ins_18_20 = ins_18_20.groupby( by = [\"ref_hash\",\"application_id\"] ).agg( {\"application_id\":\"count\"} ).rename( columns = {\"application_id\":\"cant_ins\"} ).reset_index()\n",
    "app_mas_ins_21_23 = ins_21_23.groupby( by = [\"ref_hash\",\"application_id\"] ).agg( {\"application_id\":\"count\"} ).rename( columns = {\"application_id\":\"cant_ins\"} ).reset_index()\n",
    "\n",
    "app_mas_ins_18_20 = app_mas_ins_18_20.sort_values( by = [\"ref_hash\", \"cant_ins\"], ascending = True ).drop_duplicates( subset = \"ref_hash\", keep = \"last\" ); del( app_mas_ins_18_20[\"cant_ins\"] )\n",
    "app_mas_ins_21_23 = app_mas_ins_21_23.sort_values( by = [\"ref_hash\", \"cant_ins\"], ascending = True ).drop_duplicates( subset = \"ref_hash\", keep = \"last\" ); del( app_mas_ins_21_23[\"cant_ins\"] ) \n",
    "\n",
    "main_app_18_20 = main_app_18_20.merge( app_mas_ins_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "main_app_21_23 = main_app_21_23.merge( app_mas_ins_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "main_app_18_20[\"to_count\"] = 1; main_app_18_20[\"application_id\"] = main_app_18_20[[\"application_id\", \"to_count\"]].groupby(\"application_id\").transform( \"sum\" ) / len(main_app_18_20); del(main_app_18_20[\"to_count\"])\n",
    "main_app_21_23[\"to_count\"] = 1; main_app_21_23[\"application_id\"] = main_app_21_23[[\"application_id\", \"to_count\"]].groupby(\"application_id\").transform( \"sum\" ) / len(main_app_21_23); del(main_app_21_23[\"to_count\"])\n",
    "\n",
    "main_app_21_23[\"application_id\"].fillna( main_app_21_23[\"application_id\"].isnull().sum() / len(main_app_21_23), inplace = True )\n",
    "main_app_18_20[\"application_id\"].fillna( main_app_18_20[\"application_id\"].isnull().sum() / len(main_app_18_20), inplace = True )\n",
    "\n",
    "main_app_18_20.to_csv( loc_ftr + \"\\\\main_app_18_20.csv\", index = False )\n",
    "main_app_21_23.to_csv( loc_ftr + \"\\\\main_app_21_23.csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Cantidad de instalaciones atribuidas por dispositivo** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cins_atr_18_20 = rh_18_20.copy()\n",
    "cins_atr_21_23 = rh_21_23.copy()\n",
    "\n",
    "cant_atr_ins_18_20 = ins_18_20[[\"ref_hash\", \"attributed\"]]; cant_atr_ins_18_20[\"attributed\"] = cant_atr_ins_18_20[\"attributed\"].apply( lambda x: 1 if x else 0 );\n",
    "cant_atr_ins_21_23 = ins_21_23[[\"ref_hash\", \"attributed\"]]; cant_atr_ins_21_23[\"attributed\"] = cant_atr_ins_21_23[\"attributed\"].apply( lambda x: 1 if x else 0 );\n",
    "\n",
    "cant_atr_ins_18_20 = cant_atr_ins_18_20.groupby( \"ref_hash\" ).agg( \"sum\" )\n",
    "cant_atr_ins_21_23 = cant_atr_ins_21_23.groupby( \"ref_hash\" ).agg( \"sum\" )\n",
    "\n",
    "cins_atr_18_20 = cins_atr_18_20.merge( cant_atr_ins_18_20, how = \"left\", on = \"ref_hash\" ).fillna( 0 )\n",
    "cins_atr_21_23 = cins_atr_21_23.merge( cant_atr_ins_21_23, how = \"left\", on = \"ref_hash\" ).fillna( 0 )\n",
    "\n",
    "cins_atr_18_20.to_csv( loc_ftr + \"\\\\cins_atr_18_20.csv\", index = False )\n",
    "cins_atr_21_23.to_csv( loc_ftr + \"\\\\cins_atr_21_23.csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Cantidad de instalaciones implicitas por dispositivo** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cins_imp_18_20 = rh_18_20.copy()\n",
    "cins_imp_21_23 = rh_21_23.copy()\n",
    "\n",
    "cant_imp_ins_18_20 = ins_18_20[[\"ref_hash\", \"implicit\"]]; cant_imp_ins_18_20[\"implicit\"] = cant_imp_ins_18_20[\"implicit\"].apply( lambda x: 1 if x else 0 );\n",
    "cant_imp_ins_21_23 = ins_21_23[[\"ref_hash\", \"implicit\"]]; cant_imp_ins_21_23[\"implicit\"] = cant_imp_ins_21_23[\"implicit\"].apply( lambda x: 1 if x else 0 );\n",
    "\n",
    "cant_imp_ins_18_20 = cant_imp_ins_18_20.groupby( \"ref_hash\" ).agg( \"sum\" )\n",
    "cant_imp_ins_21_23 = cant_imp_ins_21_23.groupby( \"ref_hash\" ).agg( \"sum\" )\n",
    "\n",
    "cins_imp_18_20 = cins_imp_18_20.merge( cant_imp_ins_18_20, how = \"left\", on = \"ref_hash\" ).fillna( 0 )\n",
    "cins_imp_21_23 = cins_imp_21_23.merge( cant_imp_ins_21_23, how = \"left\", on = \"ref_hash\" ).fillna( 0 )\n",
    "\n",
    "cins_imp_18_20.to_csv( loc_ftr + \"\\\\cins_imp_18_20.csv\", index = False )\n",
    "cins_imp_21_23.to_csv( loc_ftr + \"\\\\cins_imp_21_23.csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Tiempo hasta la ultima instalacion en esa ventana** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_ins_18_20 = rh_18_20.copy()\n",
    "last_ins_21_23 = rh_21_23.copy()\n",
    "\n",
    "last_installs_rh_auc_18_20 = ins_18_20[ [\"ref_hash\",\"date\"] ].sort_values( \"date\", ascending = False ).drop_duplicates( subset = \"ref_hash\", keep = \"first\" )\n",
    "last_installs_rh_auc_21_23 = ins_21_23[ [\"ref_hash\",\"date\"] ].sort_values( \"date\", ascending = False ).drop_duplicates( subset = \"ref_hash\", keep = \"first\" )\n",
    "\n",
    "last_installs_rh_auc_18_20[\"time_to_lst_ins\"] = ( pd.to_datetime( last_installs_rh_auc_18_20[\"date\"] ) -  dt.datetime( year = 2019, month = 4, day = 18 ) ).dt.total_seconds()\n",
    "last_installs_rh_auc_21_23[\"time_to_lst_ins\"] = ( pd.to_datetime( last_installs_rh_auc_21_23[\"date\"] ) -  dt.datetime( year = 2019, month = 4, day = 21 ) ).dt.total_seconds()\n",
    "\n",
    "last_installs_rh_auc_18_20.drop( \"date\", axis = 1, inplace = True )\n",
    "last_installs_rh_auc_21_23.drop( \"date\", axis = 1, inplace = True )\n",
    "\n",
    "last_ins_18_20 = last_ins_18_20.merge( last_installs_rh_auc_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "last_ins_21_23 = last_ins_21_23.merge( last_installs_rh_auc_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "#Los que tienen NaN es que nunca convirtieron. Los marcamos con el tiempo maximo\n",
    "last_ins_18_20.fillna( 3 * 24 * 3600, inplace = True )\n",
    "last_ins_21_23.fillna( 3 * 24 * 3600, inplace = True )\n",
    "\n",
    "last_ins_18_20.to_csv( loc_ftr + \"\\\\last_ins_18_20.csv\", index = False )\n",
    "last_ins_21_23.to_csv( loc_ftr + \"\\\\last_ins_21_23.csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Instalo entre 21 hs y 3 hs (Noche)** </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **Mean Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_18_20['ins_21_3'] = ( pd.to_datetime( ins_18_20['date'] ).dt.hour > 20) | ( pd.to_datetime( ins_18_20['date'] ).dt.hour < 4) \n",
    "ins_21_23['ins_21_3'] = ( pd.to_datetime( ins_21_23['date'] ).dt.hour > 20) | ( pd.to_datetime( ins_21_23['date'] ).dt.hour < 4)\n",
    "\n",
    "ins_night_18_20 = rh_18_20.copy()\n",
    "ins_night_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = ins_18_20.groupby('ref_hash').agg({'ins_21_3':'sum'}).reset_index()\n",
    "hour_mode_21_23 = ins_21_23.groupby('ref_hash').agg({'ins_21_3':'sum'}).reset_index()\n",
    "\n",
    "ins_night_18_20 = ins_night_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "ins_night_21_23 = ins_night_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "ins_night_18_20[\"ins_21_3\"] =  (ins_night_18_20[\"ins_21_3\"] > 1).astype('int8')\n",
    "ins_night_21_23[\"ins_21_3\"] =  (ins_night_21_23[\"ins_21_3\"] > 1).astype('int8')\n",
    "\n",
    "ins_night_18_20['me_ins_21_3'] = ( ins_night_18_20.groupby('ins_21_3').transform('count') ) / len(ins_night_18_20['ins_21_3'])\n",
    "ins_night_21_23['me_ins_21_3'] = ( ins_night_21_23.groupby('ins_21_3').transform('count') ) / len(ins_night_21_23['ins_21_3'])\n",
    "\n",
    "del ins_night_18_20[\"ins_21_3\"]\n",
    "del ins_night_21_23[\"ins_21_3\"]\n",
    "\n",
    "ins_night_18_20.to_csv( loc_ftr + \"\\\\ins_ngme_18_20.csv\", index = False )\n",
    "ins_night_21_23.to_csv( loc_ftr + \"\\\\ins_ngme_21_23.csv\", index = False )\n",
    "\n",
    "del ins_18_20['ins_21_3']\n",
    "del ins_21_23['ins_21_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **One-hot Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_18_20['ins_21_3'] = ( pd.to_datetime( ins_18_20['date'] ).dt.hour > 20) | ( pd.to_datetime( ins_18_20['date'] ).dt.hour < 4) \n",
    "ins_21_23['ins_21_3'] = ( pd.to_datetime( ins_21_23['date'] ).dt.hour > 20) | ( pd.to_datetime( ins_21_23['date'] ).dt.hour < 4)\n",
    "\n",
    "ins_night_18_20 = rh_18_20.copy()\n",
    "ins_night_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = ins_18_20.groupby('ref_hash').agg({'ins_21_3':'sum'}).reset_index()\n",
    "hour_mode_21_23 = ins_21_23.groupby('ref_hash').agg({'ins_21_3':'sum'}).reset_index()\n",
    "\n",
    "ins_night_18_20 = ins_night_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "ins_night_21_23 = ins_night_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "ins_night_18_20[\"ins_21_3\"] =  (ins_night_18_20[\"ins_21_3\"] > 1).astype('int8')\n",
    "ins_night_21_23[\"ins_21_3\"] =  (ins_night_21_23[\"ins_21_3\"] > 1).astype('int8')\n",
    "\n",
    "ins_night_18_20.to_csv( loc_ftr + \"\\\\ins_ngoh_18_20.csv\", index = False )\n",
    "ins_night_21_23.to_csv( loc_ftr + \"\\\\ins_ngoh_21_23.csv\", index = False )\n",
    "\n",
    "del ins_18_20['ins_21_3']\n",
    "del ins_21_23['ins_21_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Instalo entre 4 hs y 10 hs (Ma√±ana)** </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **Mean Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_18_20['ins_4_10'] = ( pd.to_datetime( ins_18_20['date'] ).dt.hour > 3) & ( pd.to_datetime( ins_18_20['date'] ).dt.hour < 11) \n",
    "ins_21_23['ins_4_10'] = ( pd.to_datetime( ins_21_23['date'] ).dt.hour > 3) & ( pd.to_datetime( ins_21_23['date'] ).dt.hour < 11)\n",
    "\n",
    "ins_morn_18_20 = rh_18_20.copy()\n",
    "ins_morn_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = ins_18_20.groupby('ref_hash').agg({'ins_4_10':'sum'}).reset_index()\n",
    "hour_mode_21_23 = ins_21_23.groupby('ref_hash').agg({'ins_4_10':'sum'}).reset_index()\n",
    "\n",
    "ins_morn_18_20 = ins_morn_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "ins_morn_21_23 = ins_morn_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "ins_morn_18_20[\"ins_4_10\"] =  (ins_morn_18_20[\"ins_4_10\"] > 1).astype('int8')\n",
    "ins_morn_21_23[\"ins_4_10\"] =  (ins_morn_21_23[\"ins_4_10\"] > 1).astype('int8')\n",
    "\n",
    "ins_morn_18_20['me_ins_4_10'] = ( ins_morn_18_20.groupby('ins_4_10').transform('count') ) / len(ins_morn_18_20['ins_4_10'])\n",
    "ins_morn_21_23['me_ins_4_10'] = ( ins_morn_21_23.groupby('ins_4_10').transform('count') ) / len(ins_morn_21_23['ins_4_10'])\n",
    "\n",
    "del ins_morn_18_20[\"ins_4_10\"]\n",
    "del ins_morn_21_23[\"ins_4_10\"]\n",
    "\n",
    "ins_morn_18_20.to_csv( loc_ftr + \"\\\\ins_mrme_18_20.csv\", index = False )\n",
    "ins_morn_21_23.to_csv( loc_ftr + \"\\\\ins_mrme_21_23.csv\", index = False )\n",
    "\n",
    "del ins_18_20['ins_4_10']\n",
    "del ins_21_23['ins_4_10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **One-hot Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_18_20['ins_4_10'] = ( pd.to_datetime( ins_18_20['date'] ).dt.hour > 3) & ( pd.to_datetime( ins_18_20['date'] ).dt.hour< 11) \n",
    "ins_21_23['ins_4_10'] = ( pd.to_datetime( ins_21_23['date'] ).dt.hour > 3) & ( pd.to_datetime( ins_21_23['date'] ).dt.hour < 11)\n",
    "\n",
    "ins_morn_18_20 = rh_18_20.copy()\n",
    "ins_morn_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = ins_18_20.groupby('ref_hash').agg({'ins_4_10':'sum'}).reset_index()\n",
    "hour_mode_21_23 = ins_21_23.groupby('ref_hash').agg({'ins_4_10':'sum'}).reset_index()\n",
    "\n",
    "ins_morn_18_20 = ins_morn_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "ins_morn_21_23 = ins_morn_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "ins_morn_18_20[\"ins_4_10\"] =  (ins_morn_18_20[\"ins_4_10\"] > 1).astype('int8')\n",
    "ins_morn_21_23[\"ins_4_10\"] =  (ins_morn_21_23[\"ins_4_10\"] > 1).astype('int8')\n",
    "\n",
    "ins_morn_18_20.to_csv( loc_ftr + \"\\\\ins_mroh_18_20.csv\", index = False )\n",
    "ins_morn_21_23.to_csv( loc_ftr + \"\\\\ins_mroh_21_23.csv\", index = False )\n",
    "\n",
    "del ins_18_20['ins_4_10']\n",
    "del ins_21_23['ins_4_10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Instalo entre 11 hs y 15 hs (Medio dia)** </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **Mean Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_18_20['ins_11_15'] = (  pd.to_datetime( ins_18_20['date'] ).dt.hour > 10) & ( pd.to_datetime( ins_18_20['date'] ).dt.hour < 16) \n",
    "ins_21_23['ins_11_15'] = (  pd.to_datetime( ins_21_23['date'] ).dt.hour > 10) & ( pd.to_datetime( ins_21_23['date'] ).dt.hour < 16)\n",
    "\n",
    "ins_midday_18_20 = rh_18_20.copy()\n",
    "ins_midday_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = ins_18_20.groupby('ref_hash').agg({'ins_11_15':'sum'}).reset_index()\n",
    "hour_mode_21_23 = ins_21_23.groupby('ref_hash').agg({'ins_11_15':'sum'}).reset_index()\n",
    "\n",
    "ins_midday_18_20 = ins_midday_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "ins_midday_21_23 = ins_midday_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "ins_midday_18_20[\"ins_11_15\"] =  (ins_midday_18_20[\"ins_11_15\"] > 1).astype('int8')\n",
    "ins_midday_21_23[\"ins_11_15\"] =  (ins_midday_21_23[\"ins_11_15\"] > 1).astype('int8')\n",
    "\n",
    "ins_midday_18_20['me_ins_11_15'] = ( ins_midday_18_20.groupby('ins_11_15').transform('count') ) / len(ins_midday_18_20['ins_11_15'])\n",
    "ins_midday_21_23['me_ins_11_15'] = ( ins_midday_21_23.groupby('ins_11_15').transform('count') ) / len(ins_midday_21_23['ins_11_15'])\n",
    "\n",
    "del ins_midday_18_20[\"ins_11_15\"]\n",
    "del ins_midday_21_23[\"ins_11_15\"]\n",
    "\n",
    "ins_midday_18_20.to_csv( loc_ftr + \"\\\\ins_mdme_18_20.csv\", index = False )\n",
    "ins_midday_21_23.to_csv( loc_ftr + \"\\\\ins_mdme_21_23.csv\", index = False )\n",
    "\n",
    "del ins_18_20['ins_11_15']\n",
    "del ins_21_23['ins_11_15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **One-hot Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_18_20['ins_11_15'] = ( pd.to_datetime( ins_18_20['date'] ).dt.hour > 10) & ( pd.to_datetime( ins_18_20['date'] ).dt.hour < 16) \n",
    "ins_21_23['ins_11_15'] = (pd.to_datetime( ins_18_20['date'] ).dt.hour > 10) & ( pd.to_datetime( ins_18_20['date'] ).dt.hour < 16)\n",
    "\n",
    "ins_midday_18_20 = rh_18_20.copy()\n",
    "ins_midday_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = ins_18_20.groupby('ref_hash').agg({'ins_11_15':'sum'}).reset_index()\n",
    "hour_mode_21_23 = ins_21_23.groupby('ref_hash').agg({'ins_11_15':'sum'}).reset_index()\n",
    "\n",
    "ins_midday_18_20 = ins_midday_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "ins_midday_21_23 = ins_midday_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "ins_midday_18_20[\"ins_11_15\"] =  (ins_midday_18_20[\"ins_11_15\"] > 1).astype('int8')\n",
    "ins_midday_21_23[\"ins_11_15\"] =  (ins_midday_21_23[\"ins_11_15\"] > 1).astype('int8')\n",
    "\n",
    "ins_midday_18_20.to_csv( loc_ftr + \"\\\\ins_mdoh_18_20.csv\", index = False )\n",
    "ins_midday_21_23.to_csv( loc_ftr + \"\\\\ins_mdoh_21_23.csv\", index = False )\n",
    "\n",
    "del ins_18_20['ins_11_15']\n",
    "del ins_21_23['ins_11_15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> **Instalo entre 16 hs y 20 hs (Tarde)** </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **Mean Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_18_20['ins_16_20'] = ( pd.to_datetime( ins_18_20['date'] ).dt.hour > 15) & ( pd.to_datetime( ins_18_20['date'] ).dt.hour < 21) \n",
    "ins_21_23['ins_16_20'] = ( pd.to_datetime( ins_21_23['date'] ).dt.hour > 15) & ( pd.to_datetime( ins_21_23['date'] ).dt.hour < 21)\n",
    "\n",
    "ins_after_18_20 = rh_18_20.copy()\n",
    "ins_after_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = ins_18_20.groupby('ref_hash').agg({'ins_16_20':'sum'}).reset_index()\n",
    "hour_mode_21_23 = ins_21_23.groupby('ref_hash').agg({'ins_16_20':'sum'}).reset_index()\n",
    "\n",
    "ins_after_18_20 = ins_after_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "ins_after_21_23 = ins_after_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "ins_after_18_20[\"ins_16_20\"] =  (ins_after_18_20[\"ins_16_20\"] > 1).astype('int8')\n",
    "ins_after_21_23[\"ins_16_20\"] =  (ins_after_21_23[\"ins_16_20\"] > 1).astype('int8')\n",
    "\n",
    "ins_after_18_20['me_ins_16_20'] = ( ins_after_18_20.groupby('ins_16_20').transform('count') ) / len(ins_after_18_20['ins_16_20'])\n",
    "ins_after_21_23['me_ins_16_20'] = ( ins_after_21_23.groupby('ins_16_20').transform('count') ) / len(ins_after_21_23['ins_16_20'])\n",
    "\n",
    "del ins_after_18_20[\"ins_16_20\"]\n",
    "del ins_after_21_23[\"ins_16_20\"]\n",
    "\n",
    "\n",
    "ins_after_18_20.to_csv( loc_ftr + \"\\\\ins_afoh_18_20.csv\", index = False )\n",
    "ins_after_21_23.to_csv( loc_ftr + \"\\\\ins_afoh_21_23.csv\", index = False )\n",
    "\n",
    "del ins_18_20['ins_16_20']\n",
    "del ins_21_23['ins_16_20']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **One-hot Encoding** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_18_20['ins_16_20'] = ( pd.to_datetime( ins_18_20['date'] ).dt.hour > 15) & ( pd.to_datetime( ins_18_20['date'] ).dt.hour < 21) \n",
    "ins_21_23['ins_16_20'] = ( pd.to_datetime( ins_21_23['date'] ).dt.hour > 15) & ( pd.to_datetime( ins_21_23['date'] ).dt.hour < 21)\n",
    "\n",
    "ins_after_18_20 = rh_18_20.copy()\n",
    "ins_after_21_23 = rh_21_23.copy()\n",
    "\n",
    "hour_mode_18_20 = ins_18_20.groupby('ref_hash').agg({'ins_16_20':'sum'}).reset_index()\n",
    "hour_mode_21_23 = ins_21_23.groupby('ref_hash').agg({'ins_16_20':'sum'}).reset_index()\n",
    "\n",
    "ins_after_18_20 = ins_after_18_20.merge( hour_mode_18_20, how = \"left\", on = \"ref_hash\" )\n",
    "ins_after_21_23 = ins_after_21_23.merge( hour_mode_21_23, how = \"left\", on = \"ref_hash\" )\n",
    "\n",
    "ins_after_18_20[\"ins_16_20\"] =  (ins_after_18_20[\"ins_16_20\"] > 1).astype('int8')\n",
    "ins_after_21_23[\"ins_16_20\"] =  (ins_after_21_23[\"ins_16_20\"] > 1).astype('int8')\n",
    "\n",
    "ins_after_18_20.to_csv( loc_ftr + \"\\\\ins_afme_18_20.csv\", index = False )\n",
    "ins_after_21_23.to_csv( loc_ftr + \"\\\\ins_afme_21_23.csv\", index = False )\n",
    "\n",
    "del ins_18_20['ins_16_20']\n",
    "del ins_21_23['ins_16_20']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
