{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings as wr\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "wr.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_lbl = r\"D:\\Documentos\\Facu\\Organizacion de Datos\\TP2\\Labels\"\n",
    "loc_ftr = r\"D:\\Documentos\\Facu\\Organizacion de Datos\\TP2\\Features\\FeaturesLocalSC\"\n",
    "\n",
    "label_trn = pd.read_csv( loc_lbl + \"\\\\label_ins_21_23.csv\" )\n",
    "label_tst = pd.read_csv( loc_lbl + \"\\\\label_ins_24_26.csv\" )\n",
    "\n",
    "X = label_trn[ [\"ref_hash\"] ]; Z = label_tst[ [\"ref_hash\"] ]\n",
    "Y = label_trn[ [\"ref_hash\",\"21_23_sc\"] ]; W = label_tst[ [\"ref_hash\",\"24_26_sc\"] ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">  Preparo los datos para predecir </span>\n",
    "Con los datos 21-23 predecimos \"24-26_sc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_var = Z; W_var = W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregamos los features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_01_Z = pd.read_csv( loc_ftr + \"\\\\auc_nght_tst.csv\" ); Z_var = Z_var.merge( ftr_01_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_02_Z = pd.read_csv( loc_ftr + \"\\\\cant_auc_tst.csv\" ); Z_var = Z_var.merge( ftr_02_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_03_Z = pd.read_csv( loc_ftr + \"\\\\cant_clk_tst.csv\" ); Z_var = Z_var.merge( ftr_03_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_04_Z = pd.read_csv( loc_ftr + \"\\\\cant_evt_tst.csv\" ); Z_var = Z_var.merge( ftr_04_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_05_Z = pd.read_csv( loc_ftr + \"\\\\cant_ins_tst.csv\" ); Z_var = Z_var.merge( ftr_05_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_06_Z = pd.read_csv( loc_ftr + \"\\\\cevt_aft_tst.csv\" ); Z_var = Z_var.merge( ftr_06_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_07_Z = pd.read_csv( loc_ftr + \"\\\\cevt_atr_tst.csv\" ); Z_var = Z_var.merge( ftr_07_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_08_Z = pd.read_csv( loc_ftr + \"\\\\cevt_mid_tst.csv\" ); Z_var = Z_var.merge( ftr_08_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_09_Z = pd.read_csv( loc_ftr + \"\\\\cevt_mor_tst.csv\" ); Z_var = Z_var.merge( ftr_09_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_10_Z = pd.read_csv( loc_ftr + \"\\\\cevt_nig_tst.csv\" ); Z_var = Z_var.merge( ftr_10_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_11_Z = pd.read_csv( loc_ftr + \"\\\\cevt_wat_tst.csv\" ); Z_var = Z_var.merge( ftr_11_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_12_Z = pd.read_csv( loc_ftr + \"\\\\cins_atr_tst.csv\" ); Z_var = Z_var.merge( ftr_12_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_13_Z = pd.read_csv( loc_ftr + \"\\\\cins_imp_tst.csv\" ); Z_var = Z_var.merge( ftr_13_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_14_Z = pd.read_csv( loc_ftr + \"\\\\clk_aftr_tst.csv\" ); Z_var = Z_var.merge( ftr_14_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_15_Z = pd.read_csv( loc_ftr + \"\\\\clk_mday_tst.csv\" ); Z_var = Z_var.merge( ftr_15_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_16_Z = pd.read_csv( loc_ftr + \"\\\\clk_morn_tst.csv\" ); Z_var = Z_var.merge( ftr_16_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_17_Z = pd.read_csv( loc_ftr + \"\\\\clk_nght_tst.csv\" ); Z_var = Z_var.merge( ftr_17_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_18_Z = pd.read_csv( loc_ftr + \"\\\\cmapw_ev_tst.csv\" ); Z_var = Z_var.merge( ftr_18_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_19_Z = pd.read_csv( loc_ftr + \"\\\\evt_a210_tst.csv\" ); Z_var = Z_var.merge( ftr_19_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_20_Z = pd.read_csv( loc_ftr + \"\\\\evt_aftr_tst.csv\" ); Z_var = Z_var.merge( ftr_20_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_21_Z = pd.read_csv( loc_ftr + \"\\\\evt_id01_tst.csv\" ); Z_var = Z_var.merge( ftr_21_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_22_Z = pd.read_csv( loc_ftr + \"\\\\evt_mday_tst.csv\" ); Z_var = Z_var.merge( ftr_22_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_23_Z = pd.read_csv( loc_ftr + \"\\\\evt_morn_tst.csv\" ); Z_var = Z_var.merge( ftr_23_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_24_Z = pd.read_csv( loc_ftr + \"\\\\evt_nght_tst.csv\" ); Z_var = Z_var.merge( ftr_24_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_25_Z = pd.read_csv( loc_ftr + \"\\\\frst_auc_tst.csv\" ); Z_var = Z_var.merge( ftr_25_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_26_Z = pd.read_csv( loc_ftr + \"\\\\frst_clk_tst.csv\" ); Z_var = Z_var.merge( ftr_26_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_27_Z = pd.read_csv( loc_ftr + \"\\\\frst_evt_tst.csv\" ); Z_var = Z_var.merge( ftr_27_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_28_Z = pd.read_csv( loc_ftr + \"\\\\frst_ins_tst.csv\" ); Z_var = Z_var.merge( ftr_28_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_29_Z = pd.read_csv( loc_ftr + \"\\\\hr_f_auc_tst.csv\" ); Z_var = Z_var.merge( ftr_29_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_30_Z = pd.read_csv( loc_ftr + \"\\\\hr_f_evt_tst.csv\" ); Z_var = Z_var.merge( ftr_30_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_31_Z = pd.read_csv( loc_ftr + \"\\\\ins_aftr_tst.csv\" ); Z_var = Z_var.merge( ftr_31_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_32_Z = pd.read_csv( loc_ftr + \"\\\\ins_mday_tst.csv\" ); Z_var = Z_var.merge( ftr_32_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_33_Z = pd.read_csv( loc_ftr + \"\\\\ins_morn_tst.csv\" ); Z_var = Z_var.merge( ftr_33_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_34_Z = pd.read_csv( loc_ftr + \"\\\\ins_nght_tst.csv\" ); Z_var = Z_var.merge( ftr_34_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_35_Z = pd.read_csv( loc_ftr + \"\\\\kind_evt_tst.csv\" ); Z_var = Z_var.merge( ftr_35_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_36_Z = pd.read_csv( loc_ftr + \"\\\\knd_levt_tst.csv\" ); Z_var = Z_var.merge( ftr_36_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_37_Z = pd.read_csv( loc_ftr + \"\\\\last_auc_tst.csv\" ); Z_var = Z_var.merge( ftr_37_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_38_Z = pd.read_csv( loc_ftr + \"\\\\last_clk_tst.csv\" ); Z_var = Z_var.merge( ftr_38_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_39_Z = pd.read_csv( loc_ftr + \"\\\\last_evt_tst.csv\" ); Z_var = Z_var.merge( ftr_39_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_40_Z = pd.read_csv( loc_ftr + \"\\\\main_ahr_tst.csv\" ); Z_var = Z_var.merge( ftr_40_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_41_Z = pd.read_csv( loc_ftr + \"\\\\main_app_tst.csv\" ); Z_var = Z_var.merge( ftr_41_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_42_Z = pd.read_csv( loc_ftr + \"\\\\mapp_evt_tst.csv\" ); Z_var = Z_var.merge( ftr_42_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_43_Z = pd.read_csv( loc_ftr + \"\\\\mapw_evt_tst.csv\" ); Z_var = Z_var.merge( ftr_43_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_44_Z = pd.read_csv( loc_ftr + \"\\\\mas1_auc_tst.csv\" ); Z_var = Z_var.merge( ftr_44_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_45_Z = pd.read_csv( loc_ftr + \"\\\\srce_auc_tst.csv\" ); Z_var = Z_var.merge( ftr_45_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_46_Z = pd.read_csv( loc_ftr + \"\\\\top3_evt_tst.csv\" ); Z_var = Z_var.merge( ftr_46_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_47_Z = pd.read_csv( loc_ftr + \"\\\\tt_3_evt_tst.csv\" ); Z_var = Z_var.merge( ftr_47_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_48_Z = pd.read_csv( loc_ftr + \"\\\\wifi_evt_tst.csv\" ); Z_var = Z_var.merge( ftr_48_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_49_Z = pd.read_csv( loc_ftr + \"\\\\wif_fevt_tst.csv\" ); Z_var = Z_var.merge( ftr_49_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_50_Z = pd.read_csv( loc_ftr + \"\\\\wif_levt_tst.csv\" ); Z_var = Z_var.merge( ftr_50_Z, how = \"inner\", on = \"ref_hash\" ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">  Preparo los datos para entrenar </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los datos 18-20 + \"21-23_sc\" entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_var = Y; X_var = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregamos los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_01_X = pd.read_csv( loc_ftr + \"\\\\auc_nght_trn.csv\" ); X_var = X_var.merge( ftr_01_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_02_X = pd.read_csv( loc_ftr + \"\\\\cant_auc_trn.csv\" ); X_var = X_var.merge( ftr_02_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_03_X = pd.read_csv( loc_ftr + \"\\\\cant_clk_trn.csv\" ); X_var = X_var.merge( ftr_03_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_04_X = pd.read_csv( loc_ftr + \"\\\\cant_evt_trn.csv\" ); X_var = X_var.merge( ftr_04_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_05_X = pd.read_csv( loc_ftr + \"\\\\cant_ins_trn.csv\" ); X_var = X_var.merge( ftr_05_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_06_X = pd.read_csv( loc_ftr + \"\\\\cevt_aft_trn.csv\" ); X_var = X_var.merge( ftr_06_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_07_X = pd.read_csv( loc_ftr + \"\\\\cevt_atr_trn.csv\" ); X_var = X_var.merge( ftr_07_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_08_X = pd.read_csv( loc_ftr + \"\\\\cevt_mid_trn.csv\" ); X_var = X_var.merge( ftr_08_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_09_X = pd.read_csv( loc_ftr + \"\\\\cevt_mor_trn.csv\" ); X_var = X_var.merge( ftr_09_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_10_X = pd.read_csv( loc_ftr + \"\\\\cevt_nig_trn.csv\" ); X_var = X_var.merge( ftr_10_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_11_X = pd.read_csv( loc_ftr + \"\\\\cevt_wat_trn.csv\" ); X_var = X_var.merge( ftr_11_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_12_X = pd.read_csv( loc_ftr + \"\\\\cins_atr_trn.csv\" ); X_var = X_var.merge( ftr_12_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_13_X = pd.read_csv( loc_ftr + \"\\\\cins_imp_trn.csv\" ); X_var = X_var.merge( ftr_13_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_14_X = pd.read_csv( loc_ftr + \"\\\\clk_aftr_trn.csv\" ); X_var = X_var.merge( ftr_14_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_15_X = pd.read_csv( loc_ftr + \"\\\\clk_mday_trn.csv\" ); X_var = X_var.merge( ftr_15_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_16_X = pd.read_csv( loc_ftr + \"\\\\clk_morn_trn.csv\" ); X_var = X_var.merge( ftr_16_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_17_X = pd.read_csv( loc_ftr + \"\\\\clk_nght_trn.csv\" ); X_var = X_var.merge( ftr_17_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_18_X = pd.read_csv( loc_ftr + \"\\\\cmapw_ev_trn.csv\" ); X_var = X_var.merge( ftr_18_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_19_X = pd.read_csv( loc_ftr + \"\\\\evt_a210_trn.csv\" ); X_var = X_var.merge( ftr_19_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_20_X = pd.read_csv( loc_ftr + \"\\\\evt_aftr_trn.csv\" ); X_var = X_var.merge( ftr_20_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_21_X = pd.read_csv( loc_ftr + \"\\\\evt_id01_trn.csv\" ); X_var = X_var.merge( ftr_21_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_22_X = pd.read_csv( loc_ftr + \"\\\\evt_mday_trn.csv\" ); X_var = X_var.merge( ftr_22_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_23_X = pd.read_csv( loc_ftr + \"\\\\evt_morn_trn.csv\" ); X_var = X_var.merge( ftr_23_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_24_X = pd.read_csv( loc_ftr + \"\\\\evt_nght_trn.csv\" ); X_var = X_var.merge( ftr_24_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_25_X = pd.read_csv( loc_ftr + \"\\\\frst_auc_trn.csv\" ); X_var = X_var.merge( ftr_25_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_26_X = pd.read_csv( loc_ftr + \"\\\\frst_clk_trn.csv\" ); X_var = X_var.merge( ftr_26_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_27_X = pd.read_csv( loc_ftr + \"\\\\frst_evt_trn.csv\" ); X_var = X_var.merge( ftr_27_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_28_X = pd.read_csv( loc_ftr + \"\\\\frst_ins_trn.csv\" ); X_var = X_var.merge( ftr_28_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_29_X = pd.read_csv( loc_ftr + \"\\\\hr_f_auc_trn.csv\" ); X_var = X_var.merge( ftr_29_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_30_X = pd.read_csv( loc_ftr + \"\\\\hr_f_evt_trn.csv\" ); X_var = X_var.merge( ftr_30_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_31_X = pd.read_csv( loc_ftr + \"\\\\ins_aftr_trn.csv\" ); X_var = X_var.merge( ftr_31_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_32_X = pd.read_csv( loc_ftr + \"\\\\ins_mday_trn.csv\" ); X_var = X_var.merge( ftr_32_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_33_X = pd.read_csv( loc_ftr + \"\\\\ins_morn_trn.csv\" ); X_var = X_var.merge( ftr_33_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_34_X = pd.read_csv( loc_ftr + \"\\\\ins_nght_trn.csv\" ); X_var = X_var.merge( ftr_34_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_35_X = pd.read_csv( loc_ftr + \"\\\\kind_evt_trn.csv\" ); X_var = X_var.merge( ftr_35_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_36_X = pd.read_csv( loc_ftr + \"\\\\knd_levt_trn.csv\" ); X_var = X_var.merge( ftr_36_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_37_X = pd.read_csv( loc_ftr + \"\\\\last_auc_trn.csv\" ); X_var = X_var.merge( ftr_37_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_38_X = pd.read_csv( loc_ftr + \"\\\\last_clk_trn.csv\" ); X_var = X_var.merge( ftr_38_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_39_X = pd.read_csv( loc_ftr + \"\\\\last_evt_trn.csv\" ); X_var = X_var.merge( ftr_39_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_40_X = pd.read_csv( loc_ftr + \"\\\\main_ahr_trn.csv\" ); X_var = X_var.merge( ftr_40_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_41_X = pd.read_csv( loc_ftr + \"\\\\main_app_trn.csv\" ); X_var = X_var.merge( ftr_41_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_42_X = pd.read_csv( loc_ftr + \"\\\\mapp_evt_trn.csv\" ); X_var = X_var.merge( ftr_42_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_43_X = pd.read_csv( loc_ftr + \"\\\\mapw_evt_trn.csv\" ); X_var = X_var.merge( ftr_43_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_44_X = pd.read_csv( loc_ftr + \"\\\\mas1_auc_trn.csv\" ); X_var = X_var.merge( ftr_44_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_45_X = pd.read_csv( loc_ftr + \"\\\\srce_auc_trn.csv\" ); X_var = X_var.merge( ftr_45_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_46_X = pd.read_csv( loc_ftr + \"\\\\top3_evt_trn.csv\" ); X_var = X_var.merge( ftr_46_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_47_X = pd.read_csv( loc_ftr + \"\\\\tt_3_evt_trn.csv\" ); X_var = X_var.merge( ftr_47_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_48_X = pd.read_csv( loc_ftr + \"\\\\wifi_evt_trn.csv\" ); X_var = X_var.merge( ftr_48_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_49_X = pd.read_csv( loc_ftr + \"\\\\wif_fevt_trn.csv\" ); X_var = X_var.merge( ftr_49_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_50_X = pd.read_csv( loc_ftr + \"\\\\wif_levt_trn.csv\" ); X_var = X_var.merge( ftr_50_X, how = \"inner\", on = \"ref_hash\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_var = X_var.merge( Y_var, how = \"inner\", on = \"ref_hash\" ); \n",
    "Z_var = Z_var.merge( W_var, how = \"inner\", on = \"ref_hash\" ); \n",
    "\n",
    "Y_var = X_var[ [\"21_23_sc\"] ]; X_var = X_var.drop( [\"ref_hash\", \"21_23_sc\"], axis = 1 )\n",
    "W_var = Z_var[ [\"24_26_sc\"] ]; Z_var = Z_var.drop( [\"ref_hash\", \"24_26_sc\"], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X_var.columns:\n",
    "    X_var[column] = X_var[column].fillna((X_var[column].mean()))\n",
    "\n",
    "for column in Z_var.columns:\n",
    "    Z_var[column] = Z_var[column].fillna((Z_var[column].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_var = X_var.drop('evt_16_20', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediccion con <span style=\"color:green\"> *AdaBoosting*</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 97782.240633\n"
     ]
    }
   ],
   "source": [
    "estimator = AdaBoostRegressor(base_estimator=None, learning_rate=1.5, loss='linear',\n",
    "        n_estimators=50, random_state=50)\n",
    "fit = estimator.fit( X_var,Y_var )\n",
    "prd = estimator.predict( Z_var)\n",
    "rmse = np.sqrt( mean_squared_error(W_var, prd) )\n",
    "print(\"RMSE: %f\" % (rmse) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probamos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sort\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "thresholds = sort(fit.feature_importances_)\n",
    "i = 0; pred = []; mod_sel = [];\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(fit, threshold=thresh, prefit=True)\n",
    "    select_X = selection.transform(X_var)\n",
    "    # train model\n",
    "    selection_model = xgb.XGBRegressor( **prm )\n",
    "    mod_sel.append( selection_model.fit(select_X, Y_var) )\n",
    "    # eval model\n",
    "    select_Z = selection.transform(Z_var)\n",
    "    pred.append( selection_model.predict(select_Z) )\n",
    "    rmse = np.sqrt( mean_squared_error(pred[i], W_var) )\n",
    "    print(\"Thresh=%.3f, n=%d, RMSE:%f, model=%d\" % (thresh, select_X.shape[1], rmse, i) )\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning de HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "||            Results from Grid Search                  ||\n",
      "==========================================================\n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " AdaBoostRegressor(base_estimator=None, learning_rate=1.5, loss='linear',\n",
      "         n_estimators=50, random_state=50)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " -5975481226.249264\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'random_state': 50, 'n_estimators': 50, 'loss': 'linear', 'learning_rate': 1.5, 'base_estimator': None}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "mse = make_scorer( mean_squared_error, greater_is_better = False )\n",
    "\n",
    "reg = AdaBoostRegressor()\n",
    "\n",
    "tune_prms = {'base_estimator':[None], \n",
    "             'learning_rate':[1.5], \n",
    "             'loss':['linear', 'square','exponential'],\n",
    "             'n_estimators':[25,50,100,150,250,500],\n",
    "             'random_state':[1,5,10,15,20,30,40,50,75,100]\n",
    "            }\n",
    "\n",
    "grid = RandomizedSearchCV( estimator = reg, param_distributions = tune_prms, cv = 10, n_jobs = 1, scoring = mse, n_iter = 20 ) \n",
    "grid.fit( X_var, Y_var )    \n",
    "\n",
    "# Results from Grid Search\n",
    "print(\"==========================================================\")\n",
    "print(\"||            Results from Grid Search                  ||\")\n",
    "print(\"==========================================================\")    \n",
    "    \n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
