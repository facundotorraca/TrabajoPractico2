{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_lbl = r\"D:\\FacundoTorraca\\Documents\\TP2_Machine_Learning\\Labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_ftr = r\"D:\\FacundoTorraca\\Documents\\TP2_Machine_Learning\\Features\\ftr_ins\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_lb = pd.read_csv( loc_lbl + \"\\\\ins_lb.csv\", dtype = {\"obs_18_20\":\"bool\", \"obs_21_23\":\"bool\", \"obs_24_26\":\"bool\"} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro de manera que tenga los datos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_18_20 = pd.read_csv( \"D:\\FacundoTorraca\\Documents\\TP2_Machine_Learning\\Training Sets\\ins_18_20.csv\" ); rh_18_20 = rh_18_20[\"ref_hash\"].drop_duplicates().tolist()\n",
    "rh_21_23 = pd.read_csv( \"D:\\FacundoTorraca\\Documents\\TP2_Machine_Learning\\Training Sets\\ins_21_23.csv\" ); rh_21_23 = rh_21_23[\"ref_hash\"].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trn = ins_lb.loc[ ins_lb[\"ref_hash\"].isin( rh_18_20 ), [\"ref_hash\", \"21_23_sc\"] ]\n",
    "set_tst = ins_lb.loc[ ins_lb[\"ref_hash\"].isin( rh_21_23 ), [\"ref_hash\", \"24_26_sc\"] ]\n",
    "\n",
    "t_lim = 259200; max_t = 400\n",
    "set_trn_loc = pd.concat( [ set_trn.loc[ set_trn[\"21_23_sc\"] < t_lim ], set_trn.loc[ set_trn[\"21_23_sc\"] == t_lim ].reset_index( drop = True ).loc[: max_t] ], axis = 0 ).sample(frac=1).reset_index(drop=True)\n",
    "set_tst_loc = pd.concat( [ set_tst.loc[ set_tst[\"24_26_sc\"] < t_lim ], set_tst.loc[ set_tst[\"24_26_sc\"] == t_lim ].reset_index( drop = True ).loc[: max_t] ], axis = 0 ).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos los Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = set_tst[ [\"ref_hash\"] ] #Datos test\n",
    "W = set_tst[ [\"ref_hash\",\"24_26_sc\"] ] #Label test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = set_trn[ [\"ref_hash\"] ] #Datos train\n",
    "Y = set_trn[ [\"ref_hash\",\"21_23_sc\"] ] #Label train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_loc = set_tst_loc[ [\"ref_hash\"] ] #Datos test reducido\n",
    "W_loc = set_tst_loc[ [\"ref_hash\",\"24_26_sc\"] ] #Label test reducido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_loc = set_trn_loc[ [\"ref_hash\"] ] #Datos train reducido\n",
    "Y_loc = set_trn_loc[ [\"ref_hash\",\"21_23_sc\"] ] #Label train reducido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">  Preparo los datos para predecir </span>\n",
    "Con los datos 21-23 predecimos \"24-26_sc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_var = Z_loc\n",
    "W_var = W_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregamos los features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_01_Z = pd.read_csv( loc_ftr + \"\\\\sin_hour_21_23.csv\" ); Z_var = Z_var.merge( ftr_01_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_02_Z = pd.read_csv( loc_ftr + \"\\\\cant_ins_21_23.csv\" ); Z_var = Z_var.merge( ftr_02_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_03_Z = pd.read_csv( loc_ftr + \"\\\\cins_imp_21_23.csv\" ); Z_var = Z_var.merge( ftr_03_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_04_Z = pd.read_csv( loc_ftr + \"\\\\cant_evt_21_23.csv\" ); Z_var = Z_var.merge( ftr_04_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_05_Z = pd.read_csv( loc_ftr + \"\\\\cant_auc_21_23.csv\" ); Z_var = Z_var.merge( ftr_05_Z, how = \"inner\", on = \"ref_hash\" ) #FeaturesWorking\n",
    "ftr_06_Z = pd.read_csv( loc_ftr + \"\\\\wifi_ins_21_23.csv\" ); Z_var = Z_var.merge( ftr_06_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_07_Z = pd.read_csv( loc_ftr + \"\\\\main_app_21_23.csv\" ); Z_var = Z_var.merge( ftr_07_Z, how = \"inner\", on = \"ref_hash\" ) #FeaturesWorking \n",
    "ftr_08_Z = pd.read_csv( loc_ftr + \"\\\\type_ins_21_23.csv\" ); Z_var = Z_var.merge( ftr_08_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_09_Z = pd.read_csv( loc_ftr + \"\\\\ref_type_21_23.csv\" ); Z_var = Z_var.merge( ftr_09_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_10_Z = pd.read_csv( loc_ftr + \"\\\\ip_encod_21_23.csv\" ); Z_var = Z_var.merge( ftr_10_Z, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_11_Z = pd.read_csv( loc_ftr + \"\\\\frst_ins_21_23.csv\" ); Z_var = Z_var.merge( ftr_11_Z, how = \"inner\", on = \"ref_hash\" ) #FeaturesWorking\n",
    "ftr_12_Z = pd.read_csv( loc_ftr + \"\\\\cevt_atr_21_23.csv\" ); Z_var = Z_var.merge( ftr_12_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_13_Z = pd.read_csv( loc_ftr + \"\\\\kind_evt_21_23.csv\" ); Z_var = Z_var.merge( ftr_13_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_14_Z = pd.read_csv( loc_ftr + \"\\\\frst_auc_21_23.csv\" ); Z_var = Z_var.merge( ftr_14_Z, how = \"inner\", on = \"ref_hash\" ) #FeaturesWorking\n",
    "ftr_15_Z = pd.read_csv( loc_ftr + \"\\\\ins_ngoh_21_23.csv\" ); Z_var = Z_var.merge( ftr_15_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_16_Z = pd.read_csv( loc_ftr + \"\\\\ins_mroh_21_23.csv\" ); Z_var = Z_var.merge( ftr_16_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_17_Z = pd.read_csv( loc_ftr + \"\\\\ins_afoh_21_23.csv\" ); Z_var = Z_var.merge( ftr_17_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_18_Z = pd.read_csv( loc_ftr + \"\\\\ins_mdoh_21_23.csv\" ); Z_var = Z_var.merge( ftr_18_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_19_Z = pd.read_csv( loc_ftr + \"\\\\auc_ngme_21_23.csv\" ); Z_var = Z_var.merge( ftr_19_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_20_Z = pd.read_csv( loc_ftr + \"\\\\auc_mrme_21_23.csv\" ); Z_var = Z_var.merge( ftr_20_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_21_Z = pd.read_csv( loc_ftr + \"\\\\auc_afme_21_23.csv\" ); Z_var = Z_var.merge( ftr_21_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_22_Z = pd.read_csv( loc_ftr + \"\\\\auc_mdme_21_23.csv\" ); Z_var = Z_var.merge( ftr_22_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_23_Z = pd.read_csv( loc_ftr + \"\\\\clk_ngme_21_23.csv\" ); Z_var = Z_var.merge( ftr_23_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_24_Z = pd.read_csv( loc_ftr + \"\\\\clk_mrme_21_23.csv\" ); Z_var = Z_var.merge( ftr_24_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_25_Z = pd.read_csv( loc_ftr + \"\\\\clk_afme_21_23.csv\" ); Z_var = Z_var.merge( ftr_25_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_26_Z = pd.read_csv( loc_ftr + \"\\\\clk_mdme_21_23.csv\" ); Z_var = Z_var.merge( ftr_26_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_27_Z = pd.read_csv( loc_ftr + \"\\\\evt_ngme_21_23.csv\" ); Z_var = Z_var.merge( ftr_23_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_28_Z = pd.read_csv( loc_ftr + \"\\\\evt_mrme_21_23.csv\" ); Z_var = Z_var.merge( ftr_24_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_29_Z = pd.read_csv( loc_ftr + \"\\\\evt_afme_21_23.csv\" ); Z_var = Z_var.merge( ftr_25_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_30_Z = pd.read_csv( loc_ftr + \"\\\\evt_mdme_21_23.csv\" ); Z_var = Z_var.merge( ftr_26_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_31_Z = pd.read_csv( loc_ftr + \"\\\\frst_evt_21_23.csv\" ); Z_var = Z_var.merge( ftr_27_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_32_Z = pd.read_csv( loc_ftr + \"\\\\hr_f_evt_21_23.csv\" ); Z_var = Z_var.merge( ftr_28_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_33_Z = pd.read_csv( loc_ftr + \"\\\\last_evt_21_23.csv\" ); Z_var = Z_var.merge( ftr_29_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_34_Z = pd.read_csv( loc_ftr + \"\\\\m1oh_auc_21_23.csv\" ); Z_var = Z_var.merge( ftr_30_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_35_Z = pd.read_csv( loc_ftr + \"\\\\ins_dsua_21_23.csv\" ); Z_var = Z_var.merge( ftr_35_Z, how = \"inner\", on = \"ref_hash\" ) #FeaturesWorking\n",
    "ftr_36_Z = pd.read_csv( loc_ftr + \"\\\\frst_evt_21_23.csv\" ); Z_var = Z_var.merge( ftr_36_Z, how = \"inner\", on = \"ref_hash\" ) #FeaturesWorking\n",
    "ftr_37_Z = pd.read_csv( loc_ftr + \"\\\\atbt_ins_21_23.csv\" ); Z_var = Z_var.merge( ftr_37_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_38_Z = pd.read_csv( loc_ftr + \"\\\\cevt_atr_21_23.csv\" ); Z_var = Z_var.merge( ftr_38_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_39_Z = pd.read_csv( loc_ftr + \"\\\\mapp_evt_21_23.csv\" ); Z_var = Z_var.merge( ftr_39_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_40_Z = pd.read_csv( loc_ftr + \"\\\\wifi_evt_21_23.csv\" ); Z_var = Z_var.merge( ftr_40_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_41_Z = pd.read_csv( loc_ftr + \"\\\\frst_clk_21_23.csv\" ); Z_var = Z_var.merge( ftr_41_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_42_Z = pd.read_csv( loc_ftr + \"\\\\ins_ngoh_21_23.csv\" ); Z_var = Z_var.merge( ftr_42_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_43_Z = pd.read_csv( loc_ftr + \"\\\\ins_mroh_21_23.csv\" ); Z_var = Z_var.merge( ftr_43_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_44_Z = pd.read_csv( loc_ftr + \"\\\\ins_afoh_21_23.csv\" ); Z_var = Z_var.merge( ftr_44_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_45_Z = pd.read_csv( loc_ftr + \"\\\\ins_mdoh_21_23.csv\" ); Z_var = Z_var.merge( ftr_45_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_46_Z = pd.read_csv( loc_ftr + \"\\\\auc_ngoh_21_23.csv\" ); Z_var = Z_var.merge( ftr_46_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_47_Z = pd.read_csv( loc_ftr + \"\\\\auc_mroh_21_23.csv\" ); Z_var = Z_var.merge( ftr_47_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_48_Z = pd.read_csv( loc_ftr + \"\\\\auc_afoh_21_23.csv\" ); Z_var = Z_var.merge( ftr_48_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_49_Z = pd.read_csv( loc_ftr + \"\\\\auc_mdoh_21_23.csv\" ); Z_var = Z_var.merge( ftr_49_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_50_Z = pd.read_csv( loc_ftr + \"\\\\clk_ngoh_21_23.csv\" ); Z_var = Z_var.merge( ftr_50_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_51_Z = pd.read_csv( loc_ftr + \"\\\\clk_mroh_21_23.csv\" ); Z_var = Z_var.merge( ftr_51_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_52_Z = pd.read_csv( loc_ftr + \"\\\\clk_afoh_21_23.csv\" ); Z_var = Z_var.merge( ftr_52_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_53_Z = pd.read_csv( loc_ftr + \"\\\\clk_mdoh_21_23.csv\" ); Z_var = Z_var.merge( ftr_53_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_54_Z = pd.read_csv( loc_ftr + \"\\\\evt_ngoh_21_23.csv\" ); Z_var = Z_var.merge( ftr_54_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_55_Z = pd.read_csv( loc_ftr + \"\\\\evt_mroh_21_23.csv\" ); Z_var = Z_var.merge( ftr_55_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_56_Z = pd.read_csv( loc_ftr + \"\\\\evt_afoh_21_23.csv\" ); Z_var = Z_var.merge( ftr_56_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_57_Z = pd.read_csv( loc_ftr + \"\\\\evt_mdoh_21_23.csv\" ); Z_var = Z_var.merge( ftr_57_Z, how = \"inner\", on = \"ref_hash\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">  Preparo los datos para entrenar </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los datos 18-20 + \"21-23_sc\" entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_var = Y_loc\n",
    "X_var = X_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregamos los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_01_X = pd.read_csv( loc_ftr + \"\\\\sin_hour_18_20.csv\" ); X_var = X_var.merge( ftr_01_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_02_X = pd.read_csv( loc_ftr + \"\\\\cant_ins_18_20.csv\" ); X_var = X_var.merge( ftr_02_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_03_X = pd.read_csv( loc_ftr + \"\\\\cins_imp_18_20.csv\" ); X_var = X_var.merge( ftr_03_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_04_X = pd.read_csv( loc_ftr + \"\\\\cant_evt_18_20.csv\" ); X_var = X_var.merge( ftr_04_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_05_X = pd.read_csv( loc_ftr + \"\\\\cant_auc_18_20.csv\" ); X_var = X_var.merge( ftr_05_X, how = \"inner\", on = \"ref_hash\" ) #FeaturesWorking\n",
    "ftr_06_X = pd.read_csv( loc_ftr + \"\\\\wifi_ins_18_20.csv\" ); X_var = X_var.merge( ftr_06_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_07_X = pd.read_csv( loc_ftr + \"\\\\main_app_18_20.csv\" ); X_var = X_var.merge( ftr_07_X, how = \"inner\", on = \"ref_hash\" ) #FeaturesWorking\n",
    "ftr_08_X = pd.read_csv( loc_ftr + \"\\\\type_ins_18_20.csv\" ); X_var = X_var.merge( ftr_08_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_09_X = pd.read_csv( loc_ftr + \"\\\\ref_type_18_20.csv\" ); X_var = X_var.merge( ftr_09_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_10_X = pd.read_csv( loc_ftr + \"\\\\ip_encod_18_20.csv\" ); X_var = X_var.merge( ftr_10_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_11_X = pd.read_csv( loc_ftr + \"\\\\frst_ins_18_20.csv\" ); X_var = X_var.merge( ftr_11_X, how = \"inner\", on = \"ref_hash\" ) #FeaturesWorking\n",
    "ftr_12_X = pd.read_csv( loc_ftr + \"\\\\cevt_atr_18_20.csv\" ); X_var = X_var.merge( ftr_12_X, how = \"inner\", on = \"ref_hash\" ) \n",
    "ftr_13_X = pd.read_csv( loc_ftr + \"\\\\kind_evt_18_20.csv\" ); X_var = X_var.merge( ftr_13_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_14_X = pd.read_csv( loc_ftr + \"\\\\frst_auc_18_20.csv\" ); X_var = X_var.merge( ftr_14_X, how = \"inner\", on = \"ref_hash\" ) #FeaturesWorking\n",
    "ftr_15_X = pd.read_csv( loc_ftr + \"\\\\ins_ngme_18_20.csv\" ); X_var = X_var.merge( ftr_15_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_16_X = pd.read_csv( loc_ftr + \"\\\\ins_mrme_18_20.csv\" ); X_var = X_var.merge( ftr_16_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_17_X = pd.read_csv( loc_ftr + \"\\\\ins_afme_18_20.csv\" ); X_var = X_var.merge( ftr_17_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_18_X = pd.read_csv( loc_ftr + \"\\\\ins_mdme_18_20.csv\" ); X_var = X_var.merge( ftr_18_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_19_X = pd.read_csv( loc_ftr + \"\\\\auc_ngme_18_20.csv\" ); X_var = X_var.merge( ftr_19_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_20_X = pd.read_csv( loc_ftr + \"\\\\auc_mrme_18_20.csv\" ); X_var = X_var.merge( ftr_20_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_21_X = pd.read_csv( loc_ftr + \"\\\\auc_afme_18_20.csv\" ); X_var = X_var.merge( ftr_21_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_22_X = pd.read_csv( loc_ftr + \"\\\\auc_mdme_18_20.csv\" ); X_var = X_var.merge( ftr_22_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_23_X = pd.read_csv( loc_ftr + \"\\\\clk_ngme_18_20.csv\" ); X_var = X_var.merge( ftr_23_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_24_X = pd.read_csv( loc_ftr + \"\\\\clk_mrme_18_20.csv\" ); X_var = X_var.merge( ftr_24_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_25_X = pd.read_csv( loc_ftr + \"\\\\clk_afme_18_20.csv\" ); X_var = X_var.merge( ftr_25_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_26_X = pd.read_csv( loc_ftr + \"\\\\clk_mdme_18_20.csv\" ); X_var = X_var.merge( ftr_26_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_27_X = pd.read_csv( loc_ftr + \"\\\\evt_ngme_18_20.csv\" ); X_var = X_var.merge( ftr_23_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_28_X = pd.read_csv( loc_ftr + \"\\\\evt_mrme_18_20.csv\" ); X_var = X_var.merge( ftr_24_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_29_X = pd.read_csv( loc_ftr + \"\\\\evt_afme_18_20.csv\" ); X_var = X_var.merge( ftr_25_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_30_X = pd.read_csv( loc_ftr + \"\\\\evt_mdme_18_20.csv\" ); X_var = X_var.merge( ftr_26_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_31_X = pd.read_csv( loc_ftr + \"\\\\frst_evt_18_20.csv\" ); X_var = X_var.merge( ftr_27_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_32_X = pd.read_csv( loc_ftr + \"\\\\hr_f_evt_18_20.csv\" ); X_var = X_var.merge( ftr_28_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_33_X = pd.read_csv( loc_ftr + \"\\\\last_evt_18_20.csv\" ); X_var = X_var.merge( ftr_29_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_34_X = pd.read_csv( loc_ftr + \"\\\\m1oh_auc_18_20.csv\" ); X_var = X_var.merge( ftr_30_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_35_X = pd.read_csv( loc_ftr + \"\\\\ins_dsua_18_20.csv\" ); X_var = X_var.merge( ftr_35_X, how = \"inner\", on = \"ref_hash\" ) #FeaturesWorking\n",
    "ftr_36_X = pd.read_csv( loc_ftr + \"\\\\frst_evt_18_20.csv\" ); X_var = X_var.merge( ftr_36_X, how = \"inner\", on = \"ref_hash\" ) #FeaturesWorking\n",
    "ftr_37_X = pd.read_csv( loc_ftr + \"\\\\atbt_ins_18_20.csv\" ); X_var = X_var.merge( ftr_37_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_38_X = pd.read_csv( loc_ftr + \"\\\\cevt_atr_18_20.csv\" ); X_var = X_var.merge( ftr_38_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_39_X = pd.read_csv( loc_ftr + \"\\\\mapp_evt_18_20.csv\" ); X_var = X_var.merge( ftr_39_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_40_X = pd.read_csv( loc_ftr + \"\\\\wifi_evt_18_20.csv\" ); X_var = X_var.merge( ftr_40_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_41_X = pd.read_csv( loc_ftr + \"\\\\frst_clk_18_20.csv\" ); X_var = X_var.merge( ftr_41_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_42_X = pd.read_csv( loc_ftr + \"\\\\ins_ngoh_18_20.csv\" ); X_var = X_var.merge( ftr_42_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_43_X = pd.read_csv( loc_ftr + \"\\\\ins_mroh_18_20.csv\" ); X_var = X_var.merge( ftr_43_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_44_X = pd.read_csv( loc_ftr + \"\\\\ins_afoh_18_20.csv\" ); X_var = X_var.merge( ftr_44_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_45_X = pd.read_csv( loc_ftr + \"\\\\ins_mdoh_18_20.csv\" ); X_var = X_var.merge( ftr_45_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_46_X = pd.read_csv( loc_ftr + \"\\\\auc_ngoh_18_20.csv\" ); X_var = X_var.merge( ftr_46_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_47_X = pd.read_csv( loc_ftr + \"\\\\auc_mroh_18_20.csv\" ); X_var = X_var.merge( ftr_47_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_48_X = pd.read_csv( loc_ftr + \"\\\\auc_afoh_18_20.csv\" ); X_var = X_var.merge( ftr_48_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_49_X = pd.read_csv( loc_ftr + \"\\\\auc_mdoh_18_20.csv\" ); X_var = X_var.merge( ftr_49_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_50_X = pd.read_csv( loc_ftr + \"\\\\clk_ngoh_18_20.csv\" ); X_var = X_var.merge( ftr_50_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_51_X = pd.read_csv( loc_ftr + \"\\\\clk_mroh_18_20.csv\" ); X_var = X_var.merge( ftr_51_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_52_X = pd.read_csv( loc_ftr + \"\\\\clk_afoh_18_20.csv\" ); X_var = X_var.merge( ftr_52_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_53_X = pd.read_csv( loc_ftr + \"\\\\clk_mdoh_18_20.csv\" ); X_var = X_var.merge( ftr_53_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_54_X = pd.read_csv( loc_ftr + \"\\\\evt_ngoh_18_20.csv\" ); X_var = X_var.merge( ftr_54_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_55_X = pd.read_csv( loc_ftr + \"\\\\evt_mroh_18_20.csv\" ); X_var = X_var.merge( ftr_55_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_56_X = pd.read_csv( loc_ftr + \"\\\\evt_afoh_18_20.csv\" ); X_var = X_var.merge( ftr_56_X, how = \"inner\", on = \"ref_hash\" )\n",
    "ftr_57_X = pd.read_csv( loc_ftr + \"\\\\evt_mdoh_18_20.csv\" ); X_var = X_var.merge( ftr_57_X, how = \"inner\", on = \"ref_hash\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reacomodamos los SC para que queden junto a su ref_hash correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_var = X_var.merge( Y_var, how = \"inner\", on = \"ref_hash\" ); Y_var = X_var[ [\"21_23_sc\"] ]\n",
    "Z_var = Z_var.merge( W_var, how = \"inner\", on = \"ref_hash\" ); W_var = Z_var[ [\"24_26_sc\"] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropeamos algunos valores maximos (No convirtieron)\n",
    "\n",
    "Los \"loc\" es el DataFrame de entrenamiento recortado con 200 valores maximos (No conversion) y 3848 valores que convirtieron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_var = X_var.drop( [\"ref_hash\", \"21_23_sc\"], axis = 1 )\n",
    "Z_var = Z_var.drop( [\"ref_hash\", \"24_26_sc\"], axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediccion con <span style=\"color:green\"> *XGBoost*</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3389,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import graphviz as gr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3390,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm = {\"booster\":\"gbtree\",\n",
    "       \"objective\":\"reg:linear\",\n",
    "       \"colsample_bytree\" : 0.3, \n",
    "       \"learning_rate\" : 0.101,\n",
    "       \"max_depth\": 3,\n",
    "       \"n_estimators\" : 70,\n",
    "       \"eval_metric\": \"rmse\",\n",
    "       \"num_parallel_tree\":20,\n",
    "      }\n",
    "\n",
    "mdl = xgb.XGBRegressor( **prm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3391,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = mdl.fit( X_var,Y_var )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3392,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd = fit.predict( Z_var )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculamos el RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 83482.802933\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt( mean_squared_error(W_var, prd) )\n",
    "print(\"RMSE: %f\" % (rmse) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3337,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_000 = 77721.181949 #max depth = 2, n_stimators = 70, learning_rate = 0.080, num_parallel_tree = 35\n",
    "record_400 = 83482.802933 #max depth = 3, n_stimators = 70, learning_rate = 0.101, num_parallel_tree = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probamos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.106, n=6, RMSE:83482.802933, model=0\n",
      "Thresh=0.114, n=5, RMSE:83470.642179, model=1\n",
      "Thresh=0.116, n=4, RMSE:83388.845268, model=2\n",
      "Thresh=0.154, n=3, RMSE:83445.703339, model=3\n",
      "Thresh=0.238, n=2, RMSE:83634.950897, model=4\n",
      "Thresh=0.272, n=1, RMSE:83832.598568, model=5\n"
     ]
    }
   ],
   "source": [
    "from numpy import sort\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "thresholds = sort(fit.feature_importances_)\n",
    "i = 0; pred = []; mod_sel = [];\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(fit, threshold=thresh, prefit=True)\n",
    "    select_X = selection.transform(X_var)\n",
    "    # train model\n",
    "    selection_model = xgb.XGBRegressor( **prm )\n",
    "    mod_sel.append( selection_model.fit(select_X, Y_var) )\n",
    "    # eval model\n",
    "    select_Z = selection.transform(Z_var)\n",
    "    pred.append( selection_model.predict(select_Z) )\n",
    "    rmse = np.sqrt( mean_squared_error(pred[i], W_var) )\n",
    "    print(\"Thresh=%.3f, n=%d, RMSE:%f, model=%d\" % (thresh, select_X.shape[1], rmse, i) )\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning de HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1964,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1965,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "#greater_is_better = False -> Transformar score_function en loss_function\n",
    "mse = make_scorer( mean_squared_error, greater_is_better = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = xgb.XGBRegressor()\n",
    "\n",
    "tune_prms = {'max_depth': [1,2,3,4],\n",
    "             'learning_rate': [0.01, 0.05, 0.1,0.15],\n",
    "             'n_estimators': [80,120,200,250]\n",
    "            }\n",
    "\n",
    "grid = RandomizedSearchCV( estimator = mdl, param_distributions = tune_prms, cv = 10, n_jobs = 1, scoring = mse, n_iter = 20 ) \n",
    "grid.fit( X, Y )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results from Grid Search\n",
    "print(\"==========================================================\")\n",
    "print(\"||            Results from Grid Search                  ||\")\n",
    "print(\"==========================================================\")    \n",
    "    \n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficamos el Arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os; os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "\n",
    "dtrn = xgb.DMatrix(X_var,Y_var)\n",
    "\n",
    "xg_reg = xgb.train(params = prm, dtrain = dtrn, num_boost_round=12)\n",
    "\n",
    "xgb.plot_tree(xg_reg)\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploteamos el Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "xgb.plot_importance(fit)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
