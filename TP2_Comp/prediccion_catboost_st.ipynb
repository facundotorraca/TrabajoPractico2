{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_lbl = r\"D:\\TP2_Machine_Learning_v4\\Labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_ftr = r\"D:\\TP2_Machine_Learning_v4\\Features\\FeaturesST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_tr = r\"D:\\TP2_Machine_Learning\\Training Sets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_lb = pd.read_csv( loc_lbl + \"\\\\auc_lb.csv\", dtype = {\"obs_18_20\":\"bool\", \"obs_21_23\":\"bool\", \"obs_24_26\":\"bool\"} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro de manera que tenga los datos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_18_20 = pd.read_csv( loc_tr + \"\\\\rh_18_20_st.csv\" ).rename( columns = {\"device_id\":\"ref_hash\"} ); rh_18_20 = rh_18_20[\"ref_hash\"].drop_duplicates().tolist()\n",
    "rh_21_23 = pd.read_csv( loc_tr + \"\\\\rh_21_23_st.csv\" ).rename( columns = {\"device_id\":\"ref_hash\"} ); rh_21_23 = rh_21_23[\"ref_hash\"].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_18_20 = auc_lb.loc[ auc_lb[\"ref_hash\"].isin( rh_18_20 ), [\"ref_hash\"] ] #Datos del (18-20)\n",
    "st_21_23 = auc_lb.loc[ auc_lb[\"ref_hash\"].isin( rh_18_20 ), [\"21_23_st\"] ] #SC del (21-23)\n",
    "\n",
    "dt_21_23 = auc_lb.loc[ auc_lb[\"ref_hash\"].isin( rh_21_23 ), [\"ref_hash\"] ] #Datos del (21-23)\n",
    "st_24_26 = auc_lb.loc[ auc_lb[\"ref_hash\"].isin( rh_21_23 ), [\"24_26_st\"] ] #SC del (24-26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">  Preparo los datos para predecir </span>\n",
    "Con los datos 21-23 predecimos \"24-26_sc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trn = auc_lb.loc[ auc_lb[\"ref_hash\"].isin( rh_18_20 ), [\"ref_hash\", \"21_23_st\"] ]\n",
    "set_tst = auc_lb.loc[ auc_lb[\"ref_hash\"].isin( rh_21_23 ), [\"ref_hash\", \"24_26_st\"] ]\n",
    "\n",
    "t_lim = 259200.00\n",
    "max_t = 200\n",
    "\n",
    "set_trn_loc = pd.concat( [ set_trn.loc[ set_trn[\"21_23_st\"] < t_lim ], set_trn.loc[ set_trn[\"21_23_st\"] == t_lim ].reset_index( drop = True ).loc[: max_t] ], axis = 0 ).sample(frac=1).reset_index(drop=True) \n",
    "set_tst_loc = pd.concat( [ set_tst.loc[ set_tst[\"24_26_st\"] < t_lim ], set_tst.loc[ set_tst[\"24_26_st\"] == t_lim ].reset_index( drop = True ).loc[: max_t] ], axis = 0 ).sample(frac=1).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_loc = set_trn_loc.loc[:,['ref_hash']] #Datos train\n",
    "Y_loc = set_trn_loc.loc[:,['21_23_st']] #Label train\n",
    "\n",
    "Z_loc = set_tst_loc.loc[:,['ref_hash']] #Datos test\n",
    "W_loc = set_tst_loc.loc[:,['24_26_st']] #Label test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_loc\n",
    "Y = Y_loc\n",
    "Z = Z_loc\n",
    "W = W_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregamos los features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ftr_01_Z = pd.read_csv( loc_ftr + \"\\\\hora_auc_21_23.csv\" ) \n",
    "ftr_02_Z = pd.read_csv( loc_ftr + \"\\\\cant_clk_21_23.csv\" ) \n",
    "ftr_03_Z = pd.read_csv( loc_ftr + \"\\\\cant_ins_21_23.csv\" ) \n",
    "ftr_04_Z = pd.read_csv( loc_ftr + \"\\\\cant_auc_21_23.csv\" ) \n",
    "ftr_05_Z = pd.read_csv( loc_ftr + \"\\\\cant_evt_21_23.csv\" )\n",
    "#ftr_06_Z = pd.read_csv( loc_ftr + \"\\\\ref_type_21_23.csv\" )  \n",
    "ftr_07_Z = pd.read_csv( loc_ftr + \"\\\\sdia_auc_21_23.csv\" )\n",
    "#ftr_08_Z = pd.read_csv( loc_ftr + \"\\\\srce_auc_21_23.csv\" )\n",
    "ftr_09_Z = pd.read_csv( loc_ftr + \"\\\\rh_encod_21_23.csv\" )\n",
    "ftr_10_Z = pd.read_csv( loc_ftr + \"\\\\main_ahr_21_23.csv\" )\n",
    "ftr_11_Z = pd.read_csv( loc_ftr + \"\\\\kind_evt_21_23.csv\" )\n",
    "ftr_12_Z = pd.read_csv( loc_ftr + \"\\\\frst_auc_21_23.csv\" )\n",
    "\n",
    "ftr_13_Z = pd.read_csv( loc_ftr + \"\\\\frst_evt_21_23.csv\" )\n",
    "ftr_14_Z = pd.read_csv( loc_ftr + \"\\\\frst_ins_21_23.csv\" )\n",
    "ftr_15_Z = pd.read_csv( loc_ftr + \"\\\\frst_clk_21_23.csv\" )\n",
    "\n",
    "ftr_16_Z = pd.read_csv( loc_ftr + \"\\\\last_auc_21_23.csv\" )\n",
    "ftr_17_Z = pd.read_csv( loc_ftr + \"\\\\last_evt_21_23.csv\" )\n",
    "\n",
    "ftr_18_Z = pd.read_csv( loc_ftr + \"\\\\me_mt_1_auc_21_23.csv\" )\n",
    "ftr_19_Z = pd.read_csv( loc_ftr + \"\\\\mt_1_auc_21_23.csv\" )\n",
    "\n",
    "ftr_20_Z = pd.read_csv( loc_ftr + \"\\\\me_auc_night_21_23.csv\" )\n",
    "#ftr_21_Z = pd.read_csv( loc_ftr + \"\\\\auc_night_21_23.csv\" )\n",
    "ftr_22_Z = pd.read_csv( loc_ftr + \"\\\\me_auc_morn_21_23.csv\" )\n",
    "#ftr_23_Z = pd.read_csv( loc_ftr + \"\\\\auc_morn_21_23.csv\" )\n",
    "ftr_24_Z = pd.read_csv( loc_ftr + \"\\\\me_auc_midday_21_23.csv\" )\n",
    "#ftr_25_Z = pd.read_csv( loc_ftr + \"\\\\auc_midday_21_23.csv\" )\n",
    "ftr_26_Z = pd.read_csv( loc_ftr + \"\\\\me_auc_after_21_23.csv\" )\n",
    "#ftr_27_Z = pd.read_csv( loc_ftr + \"\\\\auc_after_21_23.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z = Z.merge( ftr_01_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_02_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_03_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_04_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_05_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "#Z = Z.merge( ftr_06_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_07_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "#Z = Z.merge( ftr_08_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_09_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_10_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_11_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_12_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "\n",
    "Z = Z.merge( ftr_13_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_14_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_15_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "\n",
    "Z = Z.merge( ftr_16_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_17_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "\n",
    "Z = Z.merge( ftr_18_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_19_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "\n",
    "Z = Z.merge( ftr_20_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "#Z = Z.merge( ftr_21_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_22_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "#Z = Z.merge( ftr_23_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_24_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "#Z = Z.merge( ftr_25_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "Z = Z.merge( ftr_26_Z, how = \"inner\", on = \"ref_hash\" )\n",
    "#Z = Z.merge( ftr_27_Z, how = \"inner\", on = \"ref_hash\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">  Preparo los datos para entrenar </span>\n",
    "\n",
    "Con los datos 18-20 + \"21-23_sc\" entrenamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregamos los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ftr_01_X = pd.read_csv( loc_ftr + \"\\\\hora_auc_18_20.csv\" ) \n",
    "ftr_02_X = pd.read_csv( loc_ftr + \"\\\\cant_clk_18_20.csv\" ) \n",
    "ftr_03_X = pd.read_csv( loc_ftr + \"\\\\cant_ins_18_20.csv\" ) \n",
    "ftr_04_X = pd.read_csv( loc_ftr + \"\\\\cant_auc_18_20.csv\" ) \n",
    "ftr_05_X = pd.read_csv( loc_ftr + \"\\\\cant_evt_18_20.csv\" )\n",
    "#ftr_06_X = pd.read_csv( loc_ftr + \"\\\\ref_type_18_20.csv\" )  \n",
    "ftr_07_X = pd.read_csv( loc_ftr + \"\\\\sdia_auc_18_20.csv\" )  \n",
    "#ftr_08_X = pd.read_csv( loc_ftr + \"\\\\srce_auc_18_20.csv\" )\n",
    "ftr_09_X = pd.read_csv( loc_ftr + \"\\\\rh_encod_18_20.csv\" )\n",
    "ftr_10_X = pd.read_csv( loc_ftr + \"\\\\main_ahr_18_20.csv\" )\n",
    "ftr_11_X = pd.read_csv( loc_ftr + \"\\\\kind_evt_18_20.csv\" )\n",
    "ftr_12_X = pd.read_csv( loc_ftr + \"\\\\frst_auc_18_20.csv\" )\n",
    "\n",
    "ftr_13_X = pd.read_csv( loc_ftr + \"\\\\frst_evt_18_20.csv\" )\n",
    "ftr_14_X = pd.read_csv( loc_ftr + \"\\\\frst_ins_18_20.csv\" )\n",
    "ftr_15_X = pd.read_csv( loc_ftr + \"\\\\frst_clk_18_20.csv\" )\n",
    "\n",
    "ftr_16_X = pd.read_csv( loc_ftr + \"\\\\last_auc_18_20.csv\" )\n",
    "ftr_17_X = pd.read_csv( loc_ftr + \"\\\\last_evt_18_20.csv\" )\n",
    "\n",
    "ftr_18_X = pd.read_csv( loc_ftr + \"\\\\me_mt_1_auc_18_20.csv\" )\n",
    "ftr_19_X = pd.read_csv( loc_ftr + \"\\\\mt_1_auc_18_20.csv\" )\n",
    "\n",
    "ftr_20_X = pd.read_csv( loc_ftr + \"\\\\me_auc_night_18_20.csv\" )\n",
    "#ftr_21_X = pd.read_csv( loc_ftr + \"\\\\auc_night_18_20.csv\" )\n",
    "ftr_22_X = pd.read_csv( loc_ftr + \"\\\\me_auc_morn_18_20.csv\" )\n",
    "#ftr_23_X = pd.read_csv( loc_ftr + \"\\\\auc_morn_18_20.csv\" )\n",
    "ftr_24_X = pd.read_csv( loc_ftr + \"\\\\me_auc_midday_18_20.csv\" )\n",
    "#ftr_25_X = pd.read_csv( loc_ftr + \"\\\\auc_midday_18_20.csv\" )\n",
    "ftr_26_X = pd.read_csv( loc_ftr + \"\\\\me_auc_after_18_20.csv\" )\n",
    "#ftr_27_X = pd.read_csv( loc_ftr + \"\\\\auc_after_18_20.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X.merge( ftr_01_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_02_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_03_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_04_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_05_X, how = \"inner\", on = \"ref_hash\" )\n",
    "#X = X.merge( ftr_06_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_07_X, how = \"inner\", on = \"ref_hash\" )\n",
    "#X = X.merge( ftr_08_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_09_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_10_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_11_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_12_X, how = \"inner\", on = \"ref_hash\" )\n",
    "\n",
    "X = X.merge( ftr_13_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_14_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_15_X, how = \"inner\", on = \"ref_hash\" )\n",
    "\n",
    "X = X.merge( ftr_16_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_17_X, how = \"inner\", on = \"ref_hash\" )\n",
    "\n",
    "X = X.merge( ftr_18_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_19_X, how = \"inner\", on = \"ref_hash\" )\n",
    "\n",
    "X = X.merge( ftr_20_X, how = \"inner\", on = \"ref_hash\" )\n",
    "#X = X.merge( ftr_21_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_22_X, how = \"inner\", on = \"ref_hash\" )\n",
    "#X = X.merge( ftr_23_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_24_X, how = \"inner\", on = \"ref_hash\" )\n",
    "#X = X.merge( ftr_25_X, how = \"inner\", on = \"ref_hash\" )\n",
    "X = X.merge( ftr_26_X, how = \"inner\", on = \"ref_hash\" )\n",
    "#X = X.merge( ftr_27_X, how = \"inner\", on = \"ref_hash\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropeamos los ref_hash (Quedan los codificados del feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop( \"ref_hash\", axis = 1 )\n",
    "Z = Z.drop( \"ref_hash\", axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediccion con <span style=\"color:green\"> *CATBOOST*</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor(iterations=200,\n",
    "                          learning_rate=0.06,\n",
    "                          depth=3,\n",
    "                          loss_function='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "model.fit(X, Y, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculamos el RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt( mean_squared_error(W, preds) )\n",
    "print(\"RMSE: %f\" % (rmse) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = 63018.200114"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X: Train Data, Y: Train Labels, Z: Test Data, sc_24_26: Test Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record = iterations=300, learning_rate=0.06, depth=3, RMSE: RMSE: 89111.002876"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters = {'depth'         : [2,3,4,6,8],\n",
    "#              'learning_rate' : [0.02, 0.05, 0.06, 0.1, 0.5],\n",
    "#              'iterations'    : [10, 30, 50, 100, 200]\n",
    "#                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "mse = make_scorer( mean_squared_error, greater_is_better = False ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = CatBoostRegressor(loss_function='RMSE')\n",
    "parameters = {'depth'         : [2,3,6,8],\n",
    "              'learning_rate' : [0.04, 0.06, 0.08, 0.1],\n",
    "              'iterations'    : [20, 50, 100, 150]\n",
    "                 }\n",
    "grid = GridSearchCV(estimator=model, scoring=mse ,param_grid = parameters, cv = 8, n_jobs=2)\n",
    "grid.fit(X, Y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Results from Grid Search\n",
    "    print(\"\\n========================================================\")\n",
    "    print(\" Results from Grid Search \" )\n",
    "    print(\"========================================================\")    \n",
    "    \n",
    "    print(\"\\n The best estimator across ALL searched params:\\n\",\n",
    "          grid.best_estimator_)\n",
    "    \n",
    "    print(\"\\n The best score across ALL searched params:\\n\",\n",
    "          grid.best_score_)\n",
    "    \n",
    "    print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "          grid.best_params_)\n",
    "    \n",
    "    print(\"\\n ========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametros encontrados con grid-searchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
